# Plan d'Impl√©mentation : Syst√®me de M√©moire Conversationnelle Multi-Niveaux

Date: 2025-12-10

## Vue d'Ensemble

Ce document d√©coupe l'impl√©mentation en √©tapes exactes, en respectant scrupuleusement la documentation √©tablie dans :
- `CONVERSATION-MEMORY-ARCHITECTURE.md`
- `EMBEDDING-GENERATION.md`
- `CONVERSATION-SUMMARIZATION.md`
- `CONVERSATION-MEMORY-ROADMAP.md`

## Architecture Cible (Rappel)

```
L0 (Turns) ‚Üí L1 (Short Term) ‚Üí L2 (Long Term)
```

**Important** : Pas de L3 - la hi√©rarchie s'arr√™te √† L2.

### Configuration des Seuils (Bas√©e sur Pourcentage)

**Contexte Maximum** : 100 000 caract√®res (configurable)
- **L1 Threshold** : 10% du contexte max = 10 000 caract√®res de conversation brute
- **L2 Threshold** : 10% du contexte max = 10 000 caract√®res de r√©sum√©s L1
- **Last User Query History** : 5% du contexte max = 5 000 caract√®res pour derni√®res requ√™tes utilisateur

**R√©partition du Contexte** :
- **5%** : Last User Query History (derni√®res requ√™tes utilisateur uniquement)
- **10%** : Recent Turns (contenu brut r√©cent avec assistant + tools)
- **10%** : Code Semantic Search (recherche s√©mantique sur code du projet, si sous-r√©pertoire et lock embeddings disponible)
- **Reste** : Semantic Search Results (turns + r√©sum√©s pertinents) + L1 Summaries Not Summarized

**Code Semantic Search** :
- **Condition** : Uniquement si on est dans un sous-r√©pertoire du projet (pas √† la racine)
- **Condition** : Uniquement si le lock d'embeddings d'ingestion est disponible (pas en cours de g√©n√©ration)
- **Filtre** : Uniquement code (Scope nodes, exclure MarkdownSection, WebPage, etc.)
- **Limite initiale** : 100 r√©sultats de recherche s√©mantique
- **Limite finale** : 10% du contexte max (10k chars) en prenant les r√©sultats avec scores les plus √©lev√©s
- **Rationale** : Contexte code pertinent directement dans la conversation, surtout pour sous-dossiers sp√©cifiques

**Rationale** :
- Gemini Flash 2.0 supporte 1M tokens (~4M caract√®res), donc 100k caract√®res est tr√®s raisonnable (~2.5% de la capacit√©)
- Co√ªt tr√®s faible : Gemini Flash 2.0 est √©conomique m√™me pour de gros contextes
- Syst√®me de pourcentage plus flexible et adaptatif
- Permet d'ajuster facilement selon besoins (ex: 5% pour conversations courtes, 15% pour longues)
- **Last User Query History** : Garde trace des derni√®res intentions/questions utilisateur pour contexte imm√©diat

### Niveaux de R√©sum√©

- **L0 (Turns)** : Contenu brut (user + assistant + tool calls + tool results)
  - Stockage : N≈ìud `Message` avec `embedding` (3072 dimensions)
  - Trigger : Stockage imm√©diat apr√®s chaque r√©ponse
  - Embedding : G√©n√©r√© √† partir de `userMessage + assistantMessage + toolResults`

- **L1 (Short Term)** : R√©sum√© de plusieurs turns
  - Stockage : N≈ìud `Summary` avec `level: 1` et `embedding` (3072 dimensions)
  - Trigger : Quand conversation brute atteint 10% du contexte max (par d√©faut: 10k chars sur 100k max)
  - Embedding : G√©n√©r√© √† partir de `summary + filesMentioned + keyFindings`

- **L2 (Long Term)** : R√©sum√© de plusieurs r√©sum√©s L1
  - Stockage : N≈ìud `Summary` avec `level: 2` et `embedding` (3072 dimensions)
  - Trigger : Quand r√©sum√©s L1 atteignent 10% du contexte max (par d√©faut: 10k chars sur 100k max)
  - Embedding : G√©n√©r√© √† partir de `summary + filesMentioned + keyFindings`

## √âtapes d'Impl√©mentation

### √âTAPE 1 : Pr√©parer les Types et Interfaces

**Fichier** : `packages/core/src/runtime/conversation/types.ts`

**Actions** :
1. V√©rifier que les types suivants existent et correspondent √† la doc :
   - `ConversationTurn` (avec `userMessage`, `assistantMessage`, `toolResults`, `timestamp`, `charCount`)
   - `ConversationSummary` (avec `summary`, `filesMentioned`, `keyFindings`, `toolsUsed`, `topics`, `level`, `charCount`)
   - `Summary` (interface pour stockage Neo4j avec `level`, `content.conversation_summary`, `content.actions_summary`, `char_range_start`, `char_range_end`, `summary_char_count`, `created_at`, `embedding`, `parent_summaries`)

2. Ajouter types manquants si n√©cessaire :
   - `ConversationSession` (avec `sessionId`, `startTime`, `lastActivity`, `cwd`, `projectPath`)
   - Types pour recherche s√©mantique : `SearchResult` avec `type: 'turn' | 'summary'`, `turn?`, `summary?`, `score`

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 54-156, 162-240

---

### √âTAPE 2 : √âtendre ConversationStorage - M√©thodes de Base

**Fichier** : `packages/core/src/runtime/conversation/storage.ts`

**Actions** :

#### 2.1 Ajouter m√©thode `storeTurn()` avec embedding L0

**Signature** :
```typescript
async storeTurn(
  sessionId: string,
  turn: ConversationTurn,
  toolCalls: ToolCall[]
): Promise<void>
```

**Impl√©mentation** :
1. Calculer `charCount` du turn : `userMessage.length + assistantMessage.length + toolResults.reduce(...)`
2. Stocker le turn dans Neo4j comme n≈ìud `Message` (ou `ConversationTurn` selon sch√©ma)
3. Stocker les `toolCalls` avec relation `HAS_TOOL_CALL`
4. G√©n√©rer embedding L0 :
   - Appeler `generateTurnEmbeddingText(turn)` (voir doc EMBEDDING-GENERATION.md ligne 74-96)
   - Utiliser `GeminiEmbeddingProvider.embedSingle()` (3072 dimensions)
   - Stocker dans propri√©t√© `embedding` du n≈ìud
5. Mettre √† jour `total_chars` de la conversation

**R√©f√©rence doc** : `EMBEDDING-GENERATION.md` lignes 70-102, `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 334-338

#### 2.2 Ajouter m√©thode `generateTurnEmbeddingText()`

**Signature** :
```typescript
private generateTurnEmbeddingText(turn: ConversationTurn): string
```

**Impl√©mentation** : Exactement comme dans `EMBEDDING-GENERATION.md` lignes 74-96

#### 2.3 Ajouter m√©thode `getRecentTurns()`

**Signature** :
```typescript
async getRecentTurns(
  sessionId: string,
  options: { maxChars?: number; limit?: number }
): Promise<ConversationTurn[]>
```

**Impl√©mentation** : Requ√™te Cypher pour r√©cup√©rer tours r√©cents non r√©sum√©s, tri√©s par timestamp DESC, limit√©s par `maxChars` et `limit`

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 244-254, 348-351

#### 2.4 Ajouter m√©thode `getLastUserQueries()`

**Signature** :
```typescript
async getLastUserQueries(
  sessionId: string,
  options: { maxChars?: number; limit?: number }
): Promise<Array<{
  userMessage: string;
  timestamp: Date | string;
  turnIndex: number;
}>>
```

**Impl√©mentation** :
1. Requ√™te Cypher pour r√©cup√©rer uniquement les messages utilisateur (role='user')
2. Trier par timestamp DESC
3. Limiter par `maxChars` (par d√©faut: 5% du contexte max = 5k chars)
4. Retourner array avec `userMessage`, `timestamp`, `turnIndex`

**Rationale** : Garde trace des derni√®res intentions/questions utilisateur pour contexte imm√©diat, s√©par√© du contexte enrichi complet

**R√©f√©rence doc** : Nouvelle fonctionnalit√©, pas dans doc originale mais logique pour contexte utilisateur

#### 2.4 Ajouter m√©thode `getRawHistoryCharCount()`

**Signature** :
```typescript
async getRawHistoryCharCount(sessionId: string): Promise<number>
```

**Impl√©mentation** : Requ√™te Cypher pour calculer somme des `charCount` des turns non r√©sum√©s (non li√©s √† un r√©sum√© L1)

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 287-297, 353

---

### √âTAPE 3 : Impl√©menter R√©sum√©s L1 Bas√©s sur Caract√®res

**Fichier** : `packages/core/src/runtime/conversation/storage.ts`

**Actions** :

#### 3.1 Ajouter m√©thode `shouldCreateL1Summary()`

**Signature** :
```typescript
async shouldCreateL1Summary(sessionId: string): Promise<{
  shouldCreate: boolean;
  charRangeStart: number;
  charRangeEnd: number;
  turnsToSummarize: ConversationTurn[];
  currentCharCount: number;
  threshold: number;
}>
```

**Impl√©mentation** :
1. Calculer `threshold` via `this.getL1Threshold()` (10% du contexte max)
2. R√©cup√©rer tous les turns non r√©sum√©s (non li√©s √† un r√©sum√© L1)
3. Calculer `charCount` cumul√© depuis le dernier r√©sum√© L1 (ou depuis le d√©but)
4. **Validation** : V√©rifier que `charCount > 0` (√©viter division par z√©ro)
5. Si `charCount >= threshold`, d√©terminer quels turns r√©sumer (jusqu'√† atteindre threshold)
6. Retourner `charRangeStart` et `charRangeEnd` (positions caract√®res dans conversation brute)
7. **Gestion erreur** : Si erreur Neo4j, retourner `shouldCreate: false` avec log

**Points de validation** :
- V√©rifier que session existe
- V√©rifier que threshold > 0
- G√©rer cas o√π aucun turn non r√©sum√©

**R√©f√©rence doc** : `CONVERSATION-SUMMARIZATION.md` lignes 59-63, `CONVERSATION-MEMORY-ROADMAP.md` lignes 9-10

#### 3.2 Modifier `storeSummary()` pour accepter r√©sum√©s L1

**V√©rifier** : La m√©thode `storeSummary()` existe d√©j√† et accepte `Summary` avec `level`, `char_range_start`, `char_range_end`, `summary_char_count`

**Si n√©cessaire** : Adapter pour stocker aussi `filesMentioned`, `keyFindings`, `toolsUsed`, `topics` (en JSON array string)

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 196-220, 340-345

#### 3.3 Ajouter m√©thode `storeSummaryWithEmbedding()`

**Signature** :
```typescript
async storeSummaryWithEmbedding(
  summary: Summary,
  filesMentioned: string[],
  keyFindings: string[],
  toolsUsed: string[],
  topics: string[]
): Promise<void>
```

**Impl√©mentation** :
1. Stocker le r√©sum√© via `storeSummary()`
2. G√©n√©rer embedding L1 :
   - Appeler `generateSummaryEmbeddingText(summary, filesMentioned, keyFindings)` (voir doc EMBEDDING-GENERATION.md ligne 109-126)
   - Utiliser `GeminiEmbeddingProvider.embedSingle()` (3072 dimensions)
   - Stocker dans propri√©t√© `embedding` du n≈ìud `Summary`
3. Cr√©er relations `SUMMARIZES` vers les turns r√©sum√©s (si level 1)
4. Cr√©er relations `MENTIONS_FILE` vers les fichiers mentionn√©s (si fichiers existent dans brain)

**R√©f√©rence doc** : `EMBEDDING-GENERATION.md` lignes 104-132, 566-795

#### 3.4 Ajouter m√©thode `generateSummaryEmbeddingText()`

**Signature** :
```typescript
private generateSummaryEmbeddingText(
  summary: Summary,
  filesMentioned: string[],
  keyFindings: string[]
): string
```

**Impl√©mentation** : Exactement comme dans `EMBEDDING-GENERATION.md` lignes 109-126

---

### √âTAPE 4 : Impl√©menter R√©sum√©s L2 Bas√©s sur Caract√®res

**Fichier** : `packages/core/src/runtime/conversation/storage.ts`

**Actions** :

#### 4.1 Ajouter m√©thode `shouldCreateL2Summary()`

**Signature** :
```typescript
async shouldCreateL2Summary(sessionId: string): Promise<{
  shouldCreate: boolean;
  summariesToSummarize: Summary[];
  charRangeStart: number;
  charRangeEnd: number;
  currentCharCount: number;
  threshold: number;
}>
```

**Impl√©mentation** :
1. Calculer `threshold` via `this.getL2Threshold()` (10% du contexte max)
2. R√©cup√©rer tous les r√©sum√©s L1 non r√©sum√©s (non li√©s √† un r√©sum√© L2)
3. Calculer `summary_char_count` cumul√© depuis le dernier r√©sum√© L2 (ou depuis le d√©but)
4. **Validation** : V√©rifier que `summary_char_count > 0` et qu'il y a au moins 2 r√©sum√©s L1
5. Si `summary_char_count >= threshold`, d√©terminer quels r√©sum√©s L1 r√©sumer
6. Retourner `charRangeStart` et `charRangeEnd` (positions caract√®res dans conversation brute originale)
7. **Gestion erreur** : Si erreur Neo4j, retourner `shouldCreate: false` avec log

**Points de validation** :
- V√©rifier que session existe
- V√©rifier qu'il y a au moins 2 r√©sum√©s L1 √† r√©sumer (sinon pas de sens)
- G√©rer cas o√π aucun r√©sum√© L1 non r√©sum√©

**R√©f√©rence doc** : `CONVERSATION-SUMMARIZATION.md` lignes 65-69, `CONVERSATION-MEMORY-ROADMAP.md` lignes 22-25

#### 4.2 Ajouter m√©thode `getLevel1SummariesNotSummarized()`

**Signature** :
```typescript
async getLevel1SummariesNotSummarized(
  sessionId: string,
  options: { limit?: number }
): Promise<Summary[]>
```

**Impl√©mentation** : Requ√™te Cypher pour r√©cup√©rer r√©sum√©s L1 non r√©sum√©s en L2, tri√©s par `created_at` DESC

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 299-311, 355-359

#### 4.3 Adapter `storeSummaryWithEmbedding()` pour L2

**Modification** : La m√©thode doit aussi g√©rer les r√©sum√©s L2 :
- Cr√©er relations `SUMMARIZES` vers les r√©sum√©s L1 r√©sum√©s (si level 2)
- Utiliser `generateL2SummaryEmbeddingText()` pour embedding (m√™me logique que L1)

**R√©f√©rence doc** : `EMBEDDING-GENERATION.md` lignes 134-163

---

### √âTAPE 5 : Impl√©menter Recherche S√©mantique Multi-Niveaux et Code Semantic Search

**Fichier** : `packages/core/src/runtime/conversation/storage.ts`

**Actions** :

#### 5.1 Ajouter m√©thode `searchConversationHistory()`

**Signature** :
```typescript
async searchConversationHistory(
  sessionId: string,
  query: string,
  options: {
    semantic?: boolean;
    maxResults?: number;
    includeTurns?: boolean;
    levels?: number[];
  }
): Promise<Array<{
  type: 'turn' | 'summary';
  turn?: ConversationTurn;
  summary?: Summary;
  score: number;
}>>
```

**Impl√©mentation** :
1. Si `semantic === true` :
   - G√©n√©rer embedding de la requ√™te via `GeminiEmbeddingProvider.embedSingle(query)`
   - Requ√™te Cypher UNION pour rechercher dans :
     - L0 (Turns) : Si `includeTurns === true` et `levels.includes(0)`
     - L1 (Summaries level 1) : Si `levels.includes(1)`
     - L2 (Summaries level 2) : Si `levels.includes(2)`
   - Utiliser `vector.similarity.cosine()` (Neo4j 5.15+) ou `gds.similarity.cosine()` (fallback)
   - Filtrer par `minScore` (par d√©faut 0.7)
   - Trier par score DESC et limiter √† `maxResults`
2. Retourner r√©sultats avec `type`, `turn` ou `summary`, et `score`

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 256-285, 361-376, `EMBEDDING-GENERATION.md` lignes 797-856

#### 5.3 Ajouter m√©thode `searchCodeSemantic()`

**Signature** :
```typescript
async searchCodeSemantic(
  query: string,
  options: {
    cwd: string;                    // Current working directory
    projectRoot: string;            // Racine du projet (pour filtrer sous-r√©pertoire)
    initialLimit?: number;          // Default: 100 r√©sultats initiaux
    maxChars?: number;              // Default: 10% du contexte max = 10k chars
    minScore?: number;              // Default: 0.3
  }
): Promise<Array<{
  scopeId: string;
  name: string;
  file: string;
  startLine: number;               // CRITIQUE : Ligne de d√©but pour √©dition directe
  endLine: number;                 // CRITIQUE : Ligne de fin pour √©dition directe
  content: string;
  score: number;
  charCount: number;
}>>
```

**Impl√©mentation** :
1. **V√©rifier conditions** :
   - V√©rifier que `cwd` est un sous-r√©pertoire de `projectRoot` (pas √©gal √† `projectRoot`)
   - V√©rifier que le lock d'embeddings d'ingestion est disponible (pass√© en param√®tre)
2. **G√©n√©rer embedding de la requ√™te** via `generateQueryEmbedding(query)`
3. **Recherche s√©mantique** :
   - Utiliser `brain_search` ou requ√™te Cypher directe sur `Scope` nodes uniquement
   - Filtrer par `file` qui commence par le chemin relatif depuis `projectRoot` vers `cwd`
   - Exclure explicitement `MarkdownSection`, `WebPage`, `DocumentFile`, etc. (uniquement `Scope`)
   - Limite initiale : `initialLimit` (100 r√©sultats)
   - Filtrer par `minScore` (0.3 par d√©faut)
4. **Trier par score DESC** et calculer `charCount` pour chaque r√©sultat
5. **Appliquer limite de caract√®res** :
   - Prendre les r√©sultats avec scores les plus √©lev√©s
   - Cumuler `charCount` jusqu'√† atteindre `maxChars` (10k chars)
   - Retourner seulement les r√©sultats qui rentrent dans la limite
6. **Retourner** array avec `scopeId`, `name`, `file`, `startLine`, `endLine`, `content` (tronqu√© si n√©cessaire), `score`, `charCount`

**Exemple de requ√™te Cypher** :
```cypher
MATCH (s:Scope)
WHERE s.embedding IS NOT NULL
  AND s.file STARTS WITH $relativePath  // Filtrer sous-r√©pertoire
  AND s.startLine IS NOT NULL           // CRITIQUE : Lignes requises pour √©dition
  AND s.endLine IS NOT NULL             // CRITIQUE : Lignes requises pour √©dition
WITH s, vector.similarity.cosine(s.embedding, $queryEmbedding) AS score
WHERE score >= $minScore
RETURN 
  s.uuid AS scopeId, 
  s.name AS name, 
  s.file AS file, 
  s.startLine AS startLine,      // CRITIQUE pour √©dition directe
  s.endLine AS endLine,          // CRITIQUE pour √©dition directe
  s.source AS content, 
  score
ORDER BY score DESC
LIMIT $initialLimit
```

**Rationale** :
- Contexte code pertinent directement dans la conversation
- Uniquement si embeddings disponibles (lock libre)
- Uniquement pour sous-r√©pertoires (√©vite trop de r√©sultats √† la racine)
- Limite intelligente : 100 r√©sultats initiaux, puis filtre par chars (10%) en gardant meilleurs scores
- **startLine/endLine** : Permet √©dition directe sans recherche suppl√©mentaire (l'agent peut utiliser `edit_file` avec lignes pr√©cises)

**R√©f√©rence doc** : Nouvelle fonctionnalit√©, utilise `brain_search` existant mais avec filtres sp√©cifiques

#### 5.2 Ajouter m√©thode helper `generateQueryEmbedding()`

**Signature** :
```typescript
private async generateQueryEmbedding(query: string): Promise<number[]>
```

**Impl√©mentation** : Utiliser `GeminiEmbeddingProvider.embedSingle(query)`

**R√©f√©rence doc** : `EMBEDDING-GENERATION.md` lignes 195-203

#### 5.3 Ajouter m√©thode `searchCodeSemantic()`

**Signature** :
```typescript
async searchCodeSemantic(
  query: string,
  options: {
    cwd: string;                    // Current working directory
    projectRoot: string;            // Racine du projet (pour filtrer sous-r√©pertoire)
    initialLimit?: number;          // Default: 100 r√©sultats initiaux
    maxChars?: number;              // Default: 10% du contexte max = 10k chars
    minScore?: number;              // Default: 0.3
  }
): Promise<Array<{
  scopeId: string;
  name: string;
  file: string;
  startLine: number;               // CRITIQUE : Ligne de d√©but pour √©dition directe
  endLine: number;                 // CRITIQUE : Ligne de fin pour √©dition directe
  content: string;
  score: number;
  charCount: number;
}>>
```

**Impl√©mentation** :
1. **V√©rifier conditions** :
   - V√©rifier que `cwd` est un sous-r√©pertoire de `projectRoot` (pas √©gal √† `projectRoot`)
   - V√©rifier que le lock d'embeddings d'ingestion est disponible (pass√© en param√®tre)
2. **G√©n√©rer embedding de la requ√™te** via `generateQueryEmbedding(query)`
3. **Recherche s√©mantique** :
   - Utiliser `brain_search` ou requ√™te Cypher directe sur `Scope` nodes uniquement
   - Filtrer par `file` qui commence par le chemin relatif depuis `projectRoot` vers `cwd`
   - Exclure explicitement `MarkdownSection`, `WebPage`, `DocumentFile`, etc. (uniquement `Scope`)
   - Limite initiale : `initialLimit` (100 r√©sultats)
   - Filtrer par `minScore` (0.3 par d√©faut)
4. **Trier par score DESC** et calculer `charCount` pour chaque r√©sultat
5. **Appliquer limite de caract√®res** :
   - Prendre les r√©sultats avec scores les plus √©lev√©s
   - Cumuler `charCount` jusqu'√† atteindre `maxChars` (10k chars)
   - Retourner seulement les r√©sultats qui rentrent dans la limite
6. **Retourner** array avec `scopeId`, `name`, `file`, `startLine`, `endLine`, `content` (tronqu√© si n√©cessaire), `score`, `charCount`

**Exemple de requ√™te Cypher** :
```cypher
MATCH (s:Scope)
WHERE s.embedding IS NOT NULL
  AND s.file STARTS WITH $relativePath  // Filtrer sous-r√©pertoire
  AND s.startLine IS NOT NULL           // CRITIQUE : Lignes requises pour √©dition
  AND s.endLine IS NOT NULL             // CRITIQUE : Lignes requises pour √©dition
WITH s, vector.similarity.cosine(s.embedding, $queryEmbedding) AS score
WHERE score >= $minScore
RETURN 
  s.uuid AS scopeId, 
  s.name AS name, 
  s.file AS file, 
  s.startLine AS startLine,      // CRITIQUE pour √©dition directe
  s.endLine AS endLine,          // CRITIQUE pour √©dition directe
  s.source AS content, 
  score
ORDER BY score DESC
LIMIT $initialLimit
```

**Rationale** :
- Contexte code pertinent directement dans la conversation
- Uniquement si embeddings disponibles (lock libre)
- Uniquement pour sous-r√©pertoires (√©vite trop de r√©sultats √† la racine)
- Limite intelligente : 100 r√©sultats initiaux, puis filtre par chars (10%) en gardant meilleurs scores
- **startLine/endLine** : Permet √©dition directe sans recherche suppl√©mentaire (l'agent peut utiliser `edit_file` avec lignes pr√©cises)

**R√©f√©rence doc** : Nouvelle fonctionnalit√©, utilise `brain_search` existant mais avec filtres sp√©cifiques

---

### √âTAPE 6 : Construire Contexte Enrichi

**Fichier** : `packages/core/src/runtime/conversation/storage.ts` ou nouveau fichier `context-builder.ts`

**Actions** :

#### 6.1 Ajouter m√©thode `buildEnrichedContext()`

**Signature** :
```typescript
async buildEnrichedContext(
  sessionId: string,
  userMessage: string,
  options?: {
    recentMaxChars?: number;
    recentLimit?: number;
    lastUserQueriesMaxChars?: number;  // Default: 5% du contexte max = 5k chars
    codeSearchMaxChars?: number;       // Default: 10% du contexte max = 10k chars
    codeSearchInitialLimit?: number;   // Default: 100 r√©sultats
    semanticMaxResults?: number;
    semanticMinScore?: number;
    level1SummariesLimit?: number;
    cwd?: string;                      // Current working directory pour d√©tecter sous-r√©pertoire
    embeddingLock?: any;               // Lock d'embeddings d'ingestion pour v√©rifier disponibilit√©
  }
): Promise<{
  lastUserQueries: Array<{
    userMessage: string;
    timestamp: Date | string;
    turnIndex: number;
  }>;
  recentTurns: ConversationTurn[];
  codeSemanticResults?: Array<{
    scopeId: string;
    name: string;
    file: string;
    startLine: number;               // CRITIQUE : Ligne de d√©but pour √©dition directe
    endLine: number;                 // CRITIQUE : Ligne de fin pour √©dition directe
    content: string;
    score: number;
    charCount: number;
  }>;
  semanticResults: Array<{
    type: 'turn' | 'summary';
    turn?: ConversationTurn;
    summary?: Summary;
    score: number;
    confidence?: number;              // Nouveau : Niveau de confiance selon source
  }>;
  level1SummariesNotSummarized: Summary[];
}>
```

**Impl√©mentation** :
1. R√©cup√©rer derni√®res requ√™tes utilisateur via `getLastUserQueries()` avec `maxChars` (par d√©faut: 5% = 5k chars)
2. R√©cup√©rer tours r√©cents via `getRecentTurns()` avec `maxChars` et `limit`
3. **Lancer recherches s√©mantiques en parall√®le** avec `Promise.all()` :
   - **Recherche s√©mantique conversation** : `searchConversationHistory()` avec `semantic: true`, `includeTurns: true`, `levels: [0, 1, 2]`
   - **Code Semantic Search** (si conditions remplies) :
     - V√©rifier que `cwd` est fourni et est un sous-r√©pertoire (pas racine du projet)
     - V√©rifier que `embeddingLock` est fourni et disponible (`!embeddingLock.isLocked()`)
     - Si conditions OK : `searchCodeSemantic()` avec `userMessage`, `initialLimit: 100`, `maxChars: 10%`
     - Sinon : `Promise.resolve([])` (array vide)
     - Filtrer uniquement sur `Scope` nodes (code), exclure `MarkdownSection`, `WebPage`, etc.
   - Les deux recherches sont ind√©pendantes et peuvent s'ex√©cuter simultan√©ment pour optimiser les performances
4. R√©cup√©rer r√©sum√©s L1 non r√©sum√©s via `getLevel1SummariesNotSummarized()`
5. Retourner objet avec les cinq composants (codeSemanticResults optionnel)

**Exemple de code** :
```typescript
const [semanticResults, codeSemanticResults] = await Promise.all([
  searchConversationHistory(sessionId, userMessage, {
    semantic: true,
    includeTurns: true,
    levels: [0, 1, 2],
    maxResults: options.semanticMaxResults,
    minScore: options.semanticMinScore
  }),
  (async () => {
    if (!options.cwd || !options.embeddingLock) return [];
    const isSubdirectory = path.relative(options.projectRoot || '', options.cwd) !== '.';
    if (!isSubdirectory || options.embeddingLock.isLocked()) return [];
    return searchCodeSemantic(userMessage, {
      cwd: options.cwd,
      projectRoot: options.projectRoot || '',
      initialLimit: options.codeSearchInitialLimit || 100,
      maxChars: options.codeSearchMaxChars || this.getCodeSearchMaxChars(),
      minScore: options.semanticMinScore || 0.3,
      embeddingLockAvailable: !options.embeddingLock.isLocked()
    });
  })()
]);
```

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 81-112 (√©tendu avec codeSemanticResults)

#### 6.2 Ajouter m√©thode `formatContextForAgent()`

**Signature** :
```typescript
formatContextForAgent(enrichedContext: {
  lastUserQueries: Array<{
    userMessage: string;
    timestamp: Date | string;
    turnIndex: number;
  }>;
  recentTurns: ConversationTurn[];
  codeSemanticResults?: Array<{
    scopeId: string;
    name: string;
    file: string;
    startLine: number;               // CRITIQUE : Ligne de d√©but pour √©dition directe
    endLine: number;                 // CRITIQUE : Ligne de fin pour √©dition directe
    content: string;
    score: number;
    charCount: number;
  }>;
  semanticResults: Array<{
    type: 'turn' | 'summary';
    turn?: ConversationTurn;
    summary?: Summary;
    score: number;
    confidence?: number;              // Nouveau : Niveau de confiance selon source
  }>;
  level1SummariesNotSummarized: Summary[];
}): string
```

**Organisation par Confidence** :
Les r√©sultats sont organis√©s par niveau de confiance pour permettre √† l'agent de prioriser les sources les plus fiables :
- **L0 (Turns)** : `confidence = 1.0` (contenu brut, source la plus fiable)
- **L1 (Summaries level 1)** : `confidence = 0.7` (r√©sum√©s r√©cents, bonne fiabilit√©)
- **L2 (Summaries level 2)** : `confidence = 0.5` (r√©sum√©s consolid√©s, fiabilit√© moyenne)
- **Code Semantic Search** : `confidence = 0.5` (code du projet, fiabilit√© moyenne)

**Impl√©mentation** : Formater avec structure suivante, organis√©e par confidence d√©croissante :
```typescript
const context = `
## Last User Queries (Recent Intentions)
${enrichedContext.lastUserQueries.map((q, i) => `
[Query ${i + 1} - Turn ${q.turnIndex}]
${q.userMessage}
`).join('\n')}

${enrichedContext.codeSemanticResults && enrichedContext.codeSemanticResults.length > 0 ? `
## Relevant Code Context (Semantic Search)
${enrichedContext.codeSemanticResults.map((code, i) => `
[${code.file}:${code.startLine}-${code.endLine}] ${code.name} (Relevance: ${(code.score * 100).toFixed(0)}%)
${code.content.substring(0, 500)}${code.content.length > 500 ? '...' : ''}
`).join('\n')}
` : ''}

## Recent Conversation (Raw)
${enrichedContext.recentTurns.map(turn => `
User: ${turn.userMessage}
Assistant: ${turn.assistantMessage}
Tools: ${turn.toolResults.map(t => t.toolName).join(', ')}
`).join('\n')}

## Relevant Past Context (Semantic Search - Turns)
${enrichedContext.semanticResults
  .filter(r => r.type === 'turn' && r.turn)
  .map(result => `
[Turn ${result.turn.turnIndex} - Relevance: ${(result.score * 100).toFixed(0)}%]
User: ${result.turn.userMessage}
Assistant: ${result.turn.assistantMessage}
Tools: ${result.turn.toolResults.map(t => t.toolName).join(', ')}
`).join('\n')}

## Relevant Past Context (Semantic Search - Summaries)
${enrichedContext.semanticResults
  .filter(r => r.type === 'summary' && r.summary)
  .map(result => `
[Level ${result.summary.level} Summary - Relevance: ${(result.score * 100).toFixed(0)}%]
${result.summary.content.conversation_summary}
${result.summary.content.actions_summary}

Key findings: ${result.summary.keyFindings?.join(', ') || 'N/A'}
Files mentioned: ${result.summary.filesMentioned?.join(', ') || 'N/A'}
`).join('\n')}

## Recent Level 1 Summaries (Not Yet Summarized to Level 2)
${enrichedContext.level1SummariesNotSummarized.map(summary => `
[Level 1 Summary]
${summary.content.conversation_summary}
${summary.content.actions_summary}

Key findings: ${summary.keyFindings?.join(', ') || 'N/A'}
Files mentioned: ${summary.filesMentioned?.join(', ') || 'N/A'}
Tools used: ${summary.toolsUsed?.join(', ') || 'N/A'}
`).join('\n')}
`;
```

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 114-156 (√©tendu avec Code Semantic Search)

---

### √âTAPE 7 : Int√©grer dans ConversationSummarizer

**Fichier** : `packages/cli/src/tui/hooks/conversation-summarizer.ts`

**Actions** :

#### 7.1 Modifier `summarizeTurns()` pour retourner format Summary

**Modification** : Adapter le retour pour correspondre √† l'interface `Summary` avec :
- `content.conversation_summary` et `content.actions_summary` (au lieu de juste `summary`)
- `char_range_start` et `char_range_end`
- `summary_char_count`
- `filesMentioned`, `keyFindings`, `toolsUsed`, `topics`

**R√©f√©rence doc** : `CONVERSATION-SUMMARIZATION.md` lignes 42-55, `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 196-220

#### 7.2 Ajouter m√©thode `summarizeSummaries()` pour L2

**Signature** :
```typescript
async summarizeSummaries(summaries: Summary[]): Promise<Summary>
```

**Impl√©mentation** : Utiliser LLM pour r√©sumer plusieurs r√©sum√©s L1 en un r√©sum√© L2, avec m√™me structure que L1

**R√©f√©rence doc** : `CONVERSATION-SUMMARIZATION.md` lignes 65-69, `CONVERSATION-MEMORY-ROADMAP.md` lignes 22-25

---

### √âTAPE 8 : Int√©grer dans useAgent.ts

**Fichier** : `packages/cli/src/tui/hooks/useAgent.ts`

**Actions** :

#### 8.1 Apr√®s chaque r√©ponse de l'agent

**Modification** :
1. Stocker le turn imm√©diatement (synchrone) via `conversationStorage.storeTurn()`
2. Lancer r√©sum√© L1 en parall√®le (asynchrone, non-bloquant) :
   ```typescript
   conversationStorage.shouldCreateL1Summary(sessionId).then(async (should) => {
     if (should.shouldCreate) {
       const summary = await summarizer.summarizeTurns(should.turnsToSummarize);
       await conversationStorage.storeSummaryWithEmbedding(summary, ...);
     }
   });
   ```
3. V√©rifier si historique brut d√©passe seuil et d√©clencher r√©sum√© L2 si n√©cessaire

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 53-79, `CONVERSATION-MEMORY-ROADMAP.md` lignes 28-45

#### 8.2 Avant chaque appel agent

**Modification** :
1. Construire contexte enrichi via `conversationStorage.buildEnrichedContext()`
2. Formater contexte via `conversationStorage.formatContextForAgent()`
3. Passer contexte enrichi √† l'agent

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 81-112

---

### √âTAPE 9 : Int√©grer dans RAG Agent

**Fichier** : `packages/core/src/runtime/agents/rag-agent.ts`

**Actions** :

#### 9.1 Modifier `ask()` pour accepter contexte enrichi

**Modification** :
1. Accepter param√®tre optionnel `enrichedContext` (ou le construire si non fourni)
2. Int√©grer le contexte enrichi dans le system prompt ou dans l'historique

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ROADMAP.md` lignes 143-177

#### 9.2 Adapter `buildHistoryContext()` pour utiliser contexte enrichi

**Modification** : Si contexte enrichi fourni, l'utiliser au lieu de construire depuis historique brut

---

### √âTAPE 10 : Gestion des Sessions par CWD

**Fichier** : `packages/core/src/runtime/conversation/storage.ts`

**Actions** :

#### 10.1 Ajouter m√©thode `createSession()`

**Signature** :
```typescript
async createSession(cwd: string, projectPath?: string): Promise<string>
```

**Impl√©mentation** :
1. Normaliser CWD (r√©soudre symlinks, chemins relatifs)
2. Cr√©er n≈ìud `ConversationSession` avec `sessionId` (UUID), `startTime`, `lastActivity`, `cwd`, `projectPath`
3. Retourner `sessionId`

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 163-170, 318

#### 10.2 Ajouter m√©thode `getSessionsByCwd()`

**Signature** :
```typescript
async getSessionsByCwd(cwd: string): Promise<Array<{
  sessionId: string;
  startTime: Date;
  lastActivity: Date;
  turnCount: number;
  lastMessage?: string;
}>>
```

**Impl√©mentation** : Requ√™te Cypher pour trouver sessions avec CWD normalis√©

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 319-325

#### 10.3 Ajouter m√©thode `loadSession()`

**Signature** :
```typescript
async loadSession(sessionId: string): Promise<{
  sessionId: string;
  cwd: string;
  projectPath?: string;
  turns: ConversationTurn[];
}>
```

**Impl√©mentation** : Charger session compl√®te avec tous ses turns

**R√©f√©rence doc** : `CONVERSATION-MEMORY-ARCHITECTURE.md` lignes 326-331

---

### √âTAPE 11 : Relations avec Fichiers Mentionn√©s

**Fichier** : `packages/core/src/runtime/conversation/storage.ts`

**Actions** :

#### 11.1 Ajouter m√©thode `findFileNode()`

**Signature** :
```typescript
private async findFileNode(
  filePath: string,
  projectRoot?: string
): Promise<{ uuid: string; path: string } | null>
```

**Impl√©mentation** : Exactement comme dans `EMBEDDING-GENERATION.md` lignes 602-636

#### 11.2 Modifier `storeSummaryWithEmbedding()` pour cr√©er relations

**Modification** : Apr√®s stockage du r√©sum√©, cr√©er relations `MENTIONS_FILE` vers fichiers mentionn√©s (si fichiers existent dans brain)

**R√©f√©rence doc** : `EMBEDDING-GENERATION.md` lignes 639-668

---

### √âTAPE 12 : Initialisation et Configuration

**Fichier** : `packages/core/src/runtime/conversation/storage.ts`

**Actions** :

#### 12.1 Ajouter constructeur avec GeminiEmbeddingProvider

**Modification** :
```typescript
constructor(
  private neo4j: Neo4jClient,
  private embeddingProvider: GeminiEmbeddingProvider,
  private config?: {
    maxContextChars?: number;           // Default: 100000 (contexte max)
    l1ThresholdPercent?: number;        // Default: 10 (10% du max = 10k chars)
    l2ThresholdPercent?: number;        // Default: 10 (10% du max = 10k chars)
    lastUserQueriesPercent?: number;    // Default: 5 (5% du max = 5k chars)
    codeSearchPercent?: number;         // Default: 10 (10% du max = 10k chars)
    codeSearchInitialLimit?: number;   // Default: 100 r√©sultats initiaux
  }
)

// Calcul des seuils r√©els
private getL1Threshold(): number {
  const max = this.config?.maxContextChars ?? 100000;
  const percent = this.config?.l1ThresholdPercent ?? 10;
  return Math.floor(max * (percent / 100));
}

private getL2Threshold(): number {
  const max = this.config?.maxContextChars ?? 100000;
  const percent = this.config?.l2ThresholdPercent ?? 10;
  return Math.floor(max * (percent / 100));
}

private getLastUserQueriesMaxChars(): number {
  const max = this.config?.maxContextChars ?? 100000;
  const percent = this.config?.lastUserQueriesPercent ?? 5;
  return Math.floor(max * (percent / 100));
}

private getCodeSearchMaxChars(): number {
  const max = this.config?.maxContextChars ?? 100000;
  const percent = this.config?.codeSearchPercent ?? 10;
  return Math.floor(max * (percent / 100));
}
```

**Avantages** :
- Plus flexible : peut ajuster selon taille de conversation
- Plus intuitif : pourcentage plut√¥t que valeur absolue
- √âconomique : 100k chars = ~25k tokens pour Gemini Flash 2.0 (tr√®s peu cher)
- **Last User Queries** : 5% d√©di√© aux derni√®res intentions utilisateur pour contexte imm√©diat
- **Code Semantic Search** : 10% d√©di√© au code pertinent du projet (si sous-r√©pertoire et embeddings disponibles)

#### 12.2 Cr√©er instance dans BrainManager ou ConversationAgent

**R√©f√©rence doc** : `EMBEDDING-GENERATION.md` lignes 165-177

---

## Ordre d'Impl√©mentation Recommand√©

1. **√âTAPE 1** : Types et interfaces (fondation)
2. **√âTAPE 2** : Stockage L0 avec embeddings (base)
3. **√âTAPE 3** : R√©sum√©s L1 bas√©s sur caract√®res (premier niveau)
4. **√âTAPE 4** : R√©sum√©s L2 bas√©s sur caract√®res (deuxi√®me niveau)
5. **√âTAPE 5** : Recherche s√©mantique multi-niveaux (recherche)
6. **√âTAPE 6** : Contexte enrichi (assemblage)
7. **√âTAPE 7** : ConversationSummarizer (adaptation)
8. **√âTAPE 8** : useAgent.ts (int√©gration CLI)
9. **√âTAPE 9** : RAG Agent (int√©gration core)
10. **√âTAPE 10** : Sessions par CWD (gestion)
11. **√âTAPE 11** : Relations fichiers (liens)
12. **√âTAPE 12** : Initialisation (finalisation)

## Points d'Attention Critiques

1. **Embeddings** : Utiliser `GeminiEmbeddingProvider` directement (pas `EmbeddingService`), 3072 dimensions
2. **Pas de hash** : Chaque turn/r√©sum√© est unique, pas besoin de hash pour cache
3. **Seuils pourcentage** : L1 bas√© sur 10% du contexte max (100k chars), L2 bas√© sur 10% du contexte max de r√©sum√©s L1
4. **Pas de L3** : S'arr√™ter √† L2
5. **Parall√©lisme** : R√©sum√©s en arri√®re-plan, non-bloquants
6. **Sch√©ma Neo4j** : Respecter exactement le sch√©ma d√©fini dans la doc (noms de n≈ìuds, propri√©t√©s, relations)
7. **formatLocalDate()** : Utiliser pour horodatage des r√©sum√©s (L1, L2)
8. **Relations** : Cr√©er `SUMMARIZES` vers turns (L1) ou summaries (L2), `MENTIONS_FILE` vers fichiers
9. **Validations** : Toujours v√©rifier existence session, threshold > 0, donn√©es non vides avant traitement
10. **Gestion erreurs** : Toutes les op√©rations doivent avoir try/catch avec fallback gracieux (ne pas bloquer l'agent)
11. **Co√ªt Gemini Flash 2.0** : 100k chars = ~25k tokens, tr√®s √©conomique m√™me pour gros contextes

## Tests √† Effectuer

### Tests Unitaires
1. Stockage d'un turn avec embedding L0
2. Calcul correct des seuils L1/L2 (10% de 100k = 10k)
3. `shouldCreateL1Summary()` retourne `true` quand seuil atteint
4. `shouldCreateL2Summary()` retourne `true` quand seuil atteint
5. `shouldCreateL2Summary()` retourne `false` si moins de 2 r√©sum√©s L1
6. G√©n√©ration embedding L0 avec format correct
7. G√©n√©ration embedding L1/L2 avec format correct
8. Recherche s√©mantique sur L0 retourne r√©sultats pertinents
9. Recherche s√©mantique sur L1 retourne r√©sultats pertinents
10. Recherche s√©mantique sur L2 retourne r√©sultats pertinents
11. `searchCodeSemantic()` retourne `[]` si `cwd === projectRoot` (pas sous-r√©pertoire)
12. `searchCodeSemantic()` retourne `[]` si `embeddingLockAvailable === false`
13. `searchCodeSemantic()` retourne r√©sultats avec `startLine` et `endLine` pr√©sents
14. `searchCodeSemantic()` filtre uniquement `Scope` nodes (pas `MarkdownSection`, etc.)
15. `searchCodeSemantic()` limite correctement √† 10% chars en gardant meilleurs scores
16. `searchCodeSemantic()` filtre correctement par chemin relatif sous-r√©pertoire

### Tests d'Int√©gration
1. G√©n√©ration automatique r√©sum√© L1 quand seuil atteint (10% de 100k)
2. G√©n√©ration automatique r√©sum√© L2 quand seuil L1 atteint (10% de 100k)
3. R√©cup√©ration Last User Queries avec limite 5% (5k chars)
4. Code Semantic Search activ√© uniquement si sous-r√©pertoire ET lock disponible
5. Code Semantic Search filtr√© uniquement sur Scope nodes (pas MarkdownSection, etc.)
6. Code Semantic Search limite correctement √† 10% chars en gardant meilleurs scores
7. Construction contexte enrichi avec tous les composants (lastUserQueries + codeSemantic + r√©cent + s√©mantique + L1)
8. Recherches s√©mantiques (conversation + code) lanc√©es en parall√®le avec `Promise.all()` pour optimiser performances
9. Format contexte pour agent correct avec Last User Queries et Code Context en premier
10. Int√©gration dans agent avec contexte enrichi
11. Gestion sessions par CWD
12. Relations avec fichiers mentionn√©s
13. Performance recherche s√©mantique < 500ms (gr√¢ce √† parall√©lisation)

### Tests de Validation
1. V√©rifier que session existe avant op√©rations
2. V√©rifier que threshold > 0 avant calculs
3. G√©rer gracieusement erreurs Neo4j (fallback sur historique brut)
4. G√©rer gracieusement erreurs g√©n√©ration embedding (ne pas bloquer)
5. G√©rer gracieusement erreurs r√©sum√© LLM (ne pas bloquer)
6. V√©rifier que charCount cumul√© est correct
7. V√©rifier que char_range_start/end sont coh√©rents

## M√©triques de Validation

- ‚úÖ Chaque turn stock√© avec embedding L0 (3072 dimensions)
- ‚úÖ R√©sum√© L1 cr√©√© automatiquement quand conversation brute atteint 10% du contexte max (10k chars sur 100k)
- ‚úÖ R√©sum√© L2 cr√©√© automatiquement quand r√©sum√©s L1 atteignent 10% du contexte max (10k chars sur 100k)
- ‚úÖ Recherche s√©mantique fonctionne sur L0, L1, L2
- ‚úÖ Contexte enrichi contient : lastUserQueries (5%) + codeSemantic (10% si conditions) + r√©cent + s√©mantique + L1 non r√©sum√©s
- ‚úÖ Last User Queries r√©cup√©r√©es (5% = 5k chars) avec derni√®res intentions utilisateur
- ‚úÖ Code Semantic Search activ√© uniquement si sous-r√©pertoire ET lock embeddings disponible
- ‚úÖ Code Semantic Search filtre uniquement Scope nodes (code), limite 100 initiaux puis 10% chars
- ‚úÖ Agent re√ßoit contexte enrichi format√© correctement avec Last User Queries et Code Context en premier
- ‚úÖ Sessions li√©es au CWD
- ‚úÖ Relations cr√©√©es avec fichiers mentionn√©s
- ‚úÖ Performance acceptable (< 500ms pour recherche s√©mantique totale gr√¢ce √† parall√©lisation)
- ‚úÖ Recherches s√©mantiques (conversation + code) lanc√©es en parall√®le avec `Promise.all()` pour optimiser les performances (les deux recherches sont ind√©pendantes et peuvent s'ex√©cuter simultan√©ment)
- ‚úÖ Gestion erreurs gracieuse (fallback, pas de blocage)
- ‚úÖ Validations correctes (session existe, threshold > 0, donn√©es non vides)

## Am√©liorations du Plan pour √âviter les Erreurs

### Validations Ajout√©es
- V√©rifier existence session avant chaque op√©ration
- V√©rifier threshold > 0 avant calculs
- V√©rifier donn√©es non vides (turns, summaries)
- V√©rifier au moins 2 r√©sum√©s L1 avant cr√©er L2

### Gestion d'Erreurs
- Try/catch sur toutes op√©rations Neo4j avec fallback
- Try/catch sur g√©n√©ration embeddings avec log (ne pas bloquer)
- Try/catch sur r√©sum√©s LLM avec fallback sur historique brut
- Logs d√©taill√©s pour debugging

### Points de V√©rification
- Chaque m√©thode v√©rifie ses pr√©conditions
- Chaque m√©thode g√®re ses erreurs
- Chaque m√©thode retourne valeurs coh√©rentes m√™me en cas d'erreur
- Tests unitaires pour chaque cas limite

## ‚ö†Ô∏è Points d'Attention Critiques Identifi√©s

### 1. Gestion de la Concurrence (Race Conditions)

**Probl√®me potentiel** :
- Si plusieurs turns arrivent rapidement, plusieurs r√©sum√©s L1 peuvent √™tre d√©clench√©s en parall√®le
- Risque de r√©sumer les m√™mes turns plusieurs fois
- Risque de d√©synchronisation des `char_range_start/end`

**Solution** : Utiliser un syst√®me de lock similaire √† `ConversationLock` (voir `EMBEDDING-ARCHITECTURE.md`)
- Lock pour L1 : Emp√™cher r√©sum√©s concurrents sur les m√™mes turns
- Lock pour L2 : Emp√™cher r√©sum√©s concurrents sur les m√™mes r√©sum√©s L1
- UUID d√©terministe bas√© sur hash du contenu pour idempotence

**Action** : Ajouter √©tape "√âTAPE 0.5 : Impl√©menter ConversationLock" avant stockage

### 2. Calcul des char_range_start/end

**Probl√®me potentiel** :
- Si un turn arrive pendant qu'un r√©sum√© L1 est en cours, le `char_range_end` peut √™tre incorrect
- Besoin de calculer positions caract√®res de mani√®re atomique

**Solution** :
- Calculer `char_range_start/end` AVANT d'acqu√©rir le lock
- Utiliser transaction Neo4j pour garantir atomicit√©
- Stocker `char_range_start` et `char_range_end` dans le r√©sum√© pour tra√ßabilit√©

**Action** : Dans `shouldCreateL1Summary()`, calculer ranges AVANT lock

### 3. Synchronisation Stockage vs R√©sum√©s

**Probl√®me potentiel** :
- Stockage turn synchrone, r√©sum√© asynchrone
- Si r√©sum√© √©choue, le turn reste non r√©sum√© mais peut √™tre compt√© dans le seuil suivant

**Solution** :
- Marquer turns comme "en cours de r√©sum√©" (flag `summarizing: true`)
- En cas d'√©chec, retirer le flag et r√©essayer au prochain tour
- Utiliser UPSERT pour r√©sum√©s (idempotent avec UUID d√©terministe)

**Action** : Ajouter flag `summarizing` aux turns dans Neo4j

### 4. Performance Requ√™tes Cypher UNION

**Probl√®me potentiel** :
- Recherche s√©mantique avec UNION sur L0 + L1 + L2 peut √™tre lente
- Plusieurs scans de graphe n√©cessaires

**Solution** :
- Utiliser index vectoriel Neo4j si disponible (`db.index.vector.queryNodes`)
- Sinon, optimiser avec `WITH` et filtres pr√©coces
- Limiter r√©sultats par niveau avant UNION
- **Parall√©lisation** : Recherches s√©mantiques conversation et code lanc√©es en parall√®le avec `Promise.all()` pour r√©duire temps total (les deux recherches sont ind√©pendantes)

**Action** : Optimiser requ√™te dans `searchConversationHistory()`, utiliser `Promise.all()` dans √©tape 6.1

### 5. Co√ªt Embeddings

**Probl√®me potentiel** :
- 3072 dimensions √ó nombre de turns/r√©sum√©s = beaucoup d'embeddings
- Co√ªt Gemini : ~$0.00001 par embedding

**Estimation** :
- 100 turns = 100 embeddings L0 = $0.001
- 10 r√©sum√©s L1 = 10 embeddings = $0.0001
- 1 r√©sum√© L2 = 1 embedding = $0.00001
- **Total pour conversation moyenne** : ~$0.0011 (tr√®s faible)

**Solution** : Acceptable, mais monitorer le co√ªt

### 6. Transition depuis Syst√®me Actuel

**Probl√®me potentiel** :
- Le syst√®me actuel utilise peut-√™tre un autre format
- Migration des donn√©es existantes n√©cessaire ?

**Solution** :
- V√©rifier compatibilit√© avec `ConversationStorage` existant
- Si migration n√©cessaire, cr√©er script de migration
- Mode "compatibilit√©" pendant transition

**Action** : Analyser code existant avant impl√©mentation

### 7. Gestion des Sessions Multiples

**Probl√®me potentiel** :
- Plusieurs sessions pour m√™me CWD
- Comment choisir quelle session charger ?

**Solution** :
- Proposer liste au d√©marrage (comme pr√©vu)
- Permettre cr√©ation nouvelle session
- Marquer session "active" vs "archived"

**Action** : Clarifier UX dans √©tape 10

### 8. Code Semantic Search - D√©tection Sous-R√©pertoire

**Probl√®me potentiel** :
- Normalisation des chemins n√©cessaire (symlinks, chemins relatifs vs absolus)
- D√©tection pr√©cise du sous-r√©pertoire peut √™tre complexe

**Solution** :
- Utiliser `path.relative(projectRoot, cwd)` pour calculer chemin relatif
- Normaliser avec `path.normalize()` et r√©soudre symlinks si n√©cessaire
- V√©rifier que `relativePath !== '.'` et `relativePath !== ''` (pas √† la racine)

**Action** : Ajouter helper `isSubdirectory(cwd, projectRoot): boolean` dans √©tape 5.3

### 9. Code Semantic Search - startLine/endLine Manquants

**Probl√®me potentiel** :
- Certains scopes peuvent ne pas avoir `startLine`/`endLine` (scopes globaux, etc.)
- Risque d'erreur si on essaie d'√©diter sans lignes

**Solution** :
- Filtrer dans requ√™te Cypher : `WHERE s.startLine IS NOT NULL AND s.endLine IS NOT NULL`
- Si scope n'a pas de lignes, ne pas l'inclure dans r√©sultats
- Logger warning si beaucoup de scopes sans lignes

**Action** : Ajouter filtres dans requ√™te Cypher √©tape 5.3

## Recommandations Finales

### ‚úÖ Points Forts √† Conserver
- Architecture claire et bien document√©e
- Syst√®me de pourcentage flexible
- Last User Queries pour contexte imm√©diat
- Validations et gestion d'erreurs pr√©vues

### üîß Am√©liorations √† Ajouter
1. **Ajouter ConversationLock** avant stockage (√©viter race conditions)
2. **Calcul atomique** des char_range_start/end
3. **Flag `summarizing`** sur turns pour √©viter doubles r√©sum√©s
4. **Optimiser requ√™tes Cypher** avec index vectoriel
5. **Script de migration** si n√©cessaire
6. **Monitoring co√ªts** embeddings
7. **Code Semantic Search** : V√©rifier conditions (sous-r√©pertoire + lock disponible) avant recherche
8. **Code Semantic Search** : Filtrer uniquement Scope nodes, exclure documents
9. **Code Semantic Search** : Limite intelligente (100 initiaux ‚Üí 10% chars avec meilleurs scores)
10. **Code Semantic Search** : Inclure `startLine` et `endLine` dans r√©sultats (CRITIQUE pour √©dition)
11. **Code Semantic Search** : Filtrer scopes sans `startLine`/`endLine` (ne pas inclure dans r√©sultats)
12. **Code Semantic Search** : Normalisation pr√©cise des chemins pour d√©tection sous-r√©pertoire

### üìä Risques Restants (Acceptables)
- Co√ªt embeddings : Tr√®s faible (~$0.001 par conversation)
- Performance : Parall√©lisation des recherches s√©mantiques r√©duit le temps total (conversation + code en m√™me temps)
- Complexit√© : Gestion des locks ajoute de la complexit√© mais n√©cessaire
- Code Semantic Search : Peut ralentir l√©g√®rement si beaucoup de r√©sultats, mais limite de 10% chars prot√®ge
- Code Semantic Search : N√©cessite d√©tection pr√©cise du sous-r√©pertoire (normalisation des chemins)
- Code Semantic Search : Certains scopes peuvent ne pas avoir `startLine`/`endLine` (filtrer dans requ√™te)

## Conclusion

Le plan est **solide et bien structur√©**, mais n√©cessite quelques ajouts pour g√©rer la concurrence et la synchronisation. Les am√©liorations propos√©es sont r√©alistes et align√©es avec les patterns existants dans le codebase (ConversationLock, IngestionLock).

**Recommandation** : Proc√©der avec le plan en ajoutant les am√©liorations critiques (locks, atomicit√©) d√®s le d√©but.
