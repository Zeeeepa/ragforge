# R√©sum√©s Hi√©rarchiques et Contexte Dual - Design D√©taill√©

## üéØ Objectifs

1. **R√©sum√©s hi√©rarchiques bas√©s sur caract√®res** - tous les niveaux (L1, L2, L3...) se cr√©ent quand un seuil de caract√®res est atteint
2. **Contexte dual** - deux sources de contexte distinctes et compl√©mentaires
3. **R√©sum√©s structur√©s** - conversation + actions s√©par√©ment
4. **Tool calls format√©s** - liens entre reasoning et tool calls

## üìä Syst√®me de R√©sum√©s Bas√© sur Caract√®res

### Principe

**Tous les niveaux** se basent sur le nombre de caract√®res, pas sur le nombre d'√©l√©ments :

```
Configuration:
- summarizeEveryNChars: 10000 (par d√©faut)

Niveau L1:
- Trigger: Tous les 10k caract√®res de conversation brute
- R√©sume: Messages bruts (user + assistant)
- Format: { conversation_summary, actions_summary }

Niveau L2:
- Trigger: Tous les 10k caract√®res de r√©sum√©s L1
- R√©sume: R√©sum√©s L1 (pas les messages!)
- Format: { conversation_summary, actions_summary }

Niveau L3:
- Trigger: Tous les 10k caract√®res de r√©sum√©s L2
- R√©sume: R√©sum√©s L2
- Format: { conversation_summary, actions_summary }

... et ainsi de suite
```

### Exemple Concret

```
Messages bruts (avec char counts):
‚îú‚îÄ Turn 1: User (500 chars) + Assistant (1500 chars) = 2000 chars
‚îú‚îÄ Turn 2: User (800 chars) + Assistant (2200 chars) = 3000 chars
‚îú‚îÄ Turn 3: User (1000 chars) + Assistant (4000 chars) = 5000 chars
‚îÇ  ‚Üí Total: 10000 chars
‚îÇ  ‚Üí TRIGGER L1 Summary #1 (chars 0-10000)
‚îÇ
‚îú‚îÄ Turn 4: User (600 chars) + Assistant (2400 chars) = 3000 chars
‚îú‚îÄ Turn 5: User (1200 chars) + Assistant (5800 chars) = 7000 chars
‚îÇ  ‚Üí Total: 20000 chars (10k nouveaux)
‚îÇ  ‚Üí TRIGGER L1 Summary #2 (chars 10000-20000)
‚îÇ
‚îú‚îÄ Turn 6-10: ... 10k chars more
‚îÇ  ‚Üí TRIGGER L1 Summary #3 (chars 20000-30000)
‚îÇ
‚îú‚îÄ Turn 11-15: ... 10k chars more
‚îÇ  ‚Üí TRIGGER L1 Summary #4 (chars 30000-40000)
‚îÇ
‚îÇ  ‚Üí CHECK L2: Summaries L1 totaux:
‚îÇ     - L1 #1: ~500 chars summary
‚îÇ     - L1 #2: ~500 chars summary
‚îÇ     - L1 #3: ~500 chars summary
‚îÇ     - L1 #4: ~500 chars summary
‚îÇ     ‚Üí Total L1 summaries chars: 2000 chars (pas encore 10k)
‚îÇ     ‚Üí PAS de L2 trigger
‚îÇ
‚îú‚îÄ Turns 16-50: ... plus de conversations
‚îÇ  ‚Üí 20 L1 summaries cr√©√©s (20 * 500 chars = 10000 chars de summaries L1)
‚îÇ  ‚Üí TRIGGER L2 Summary #1 (r√©sume L1 #1-20, covering chars 0-200000)
‚îÇ
‚îú‚îÄ Turns 51-100: ... encore plus
‚îÇ  ‚Üí 20 L1 summaries de plus (L1 #21-40)
‚îÇ  ‚Üí TRIGGER L2 Summary #2 (r√©sume L1 #21-40)
‚îÇ
‚îÇ  ‚Üí CHECK L3: Summaries L2 totaux:
‚îÇ     - L2 #1: ~500 chars
‚îÇ     - L2 #2: ~500 chars
‚îÇ     ‚Üí Total: 1000 chars (pas encore 10k)
‚îÇ     ‚Üí PAS de L3 trigger
```

### Stockage dans Neo4j

```cypher
// L1 Summary (r√©sume messages bruts)
(:Summary {
  level: 1,
  char_range_start: 0,
  char_range_end: 10000,
  content: {
    conversation_summary: "L'utilisateur a demand√© d'analyser AuthService. Je lui ai expliqu√© qu'il contient 3 fonctions principales...",
    actions_summary: "J'ai utilis√© search_functions pour trouver les fonctions (‚Üí 15 r√©sultats), puis get_function_details sur AuthService.validatePassword..."
  },
  created_at: "2025-01-15T10:00:00Z",
  parent_summaries: []  // Empty pour L1
})

// L2 Summary (r√©sume 20 L1 summaries)
(:Summary {
  level: 2,
  char_range_start: 0,          // Char range des MESSAGES originaux couverts
  char_range_end: 200000,
  content: {
    conversation_summary: "Session de refactoring d'authentification. L'utilisateur a explor√© AuthService, UserService, et TokenService...",
    actions_summary: "Recherches multiples de fonctions, analyse de d√©pendances avec get_dependents, extraction de code avec batch_analyze..."
  },
  created_at: "2025-01-15T12:00:00Z",
  parent_summaries: ["l1-uuid-1", "l1-uuid-2", ..., "l1-uuid-20"]
})
```

## üîÑ Contexte Dual - Deux Syst√®mes S√©par√©s

### Contexte 1: Recent Messages (Non-r√©sum√©s)

**But**: Garder les derniers √©changes en d√©tail pour coh√©rence imm√©diate

**Configuration**:
```typescript
config: {
  recentContextMaxChars: 5000,    // Max chars de messages r√©cents
  recentContextMaxTurns: 10       // Max nombre de turns (user+assistant)
}
```

**Fonctionnement**:
```
Toujours inclure dans le contexte:
- Les N derniers turns complets (user + assistant)
- OU jusqu'√† ce qu'on atteigne X caract√®res
- Format: Messages bruts, pas r√©sum√©s
- Ordre: Chronologique
```

**Exemple**:
```
Recent Context (derniers 3 turns):

Turn 8:
  User: "Show me the validatePassword function"
  Assistant: "Here's the code... [500 chars]"
  Reasoning: "I'll use get_function_code to retrieve it"
  Tools: [get_function_code(name="validatePassword")]

Turn 9:
  User: "What are its dependencies?"
  Assistant: "It depends on hashPassword and checkPasswordStrength... [400 chars]"
  Reasoning: "I'll use get_dependents to find them"
  Tools: [get_dependents(scopeName="validatePassword")]

Turn 10:
  User: "Suggest refactoring"
  Assistant: "I suggest splitting into... [600 chars]"
  Reasoning: "Based on complexity analysis, I'll use batch_analyze"
  Tools: [batch_analyze(...)]
```

### Contexte 2: RAG sur Summaries (Historique lointain)

**But**: R√©cup√©rer contexte pertinent des conversations pass√©es via similarit√© s√©mantique

**Configuration**:
```typescript
config: {
  ragMaxSummaries: 5,                // Top N summaries les plus pertinentes
  ragMinScore: 0.7,                  // Score minimum de similarit√©
  ragLevelBoost: {                   // Boost selon niveau
    1: 1.0,                          // L1: pas de boost
    2: 1.1,                          // L2: +10%
    3: 1.2,                          // L3: +20%
  },
  ragRecencyBoost: true,             // Boost pour summaries r√©cents
  ragRecencyDecayDays: 7             // D√©croissance sur 7 jours
}
```

**Scoring**:
```typescript
// Score final = similarity √ó levelBoost √ó recencyBoost

function calculateSummaryScore(
  summary: Summary,
  cosineSimilarity: number
): number {
  // 1. Base similarity
  let score = cosineSimilarity;

  // 2. Level boost (higher levels = plus abstrait = plus utile)
  const levelBoost = config.ragLevelBoost[summary.level] || 1.0;
  score *= levelBoost;

  // 3. Recency boost (plus r√©cent = plus pertinent)
  if (config.ragRecencyBoost) {
    const ageInDays = (Date.now() - summary.created_at) / (1000 * 60 * 60 * 24);
    const recencyBoost = Math.exp(-ageInDays / config.ragRecencyDecayDays);
    // Decay exponentiel: 1.0 (aujourd'hui) ‚Üí 0.37 (7 jours) ‚Üí 0.14 (14 jours)
    score *= (0.5 + 0.5 * recencyBoost);  // Entre 0.5x et 1.0x
  }

  return score;
}
```

**Query Flow**:
```
1. User message: "How did we handle authentication before?"

2. Generate embedding du message

3. Vector search sur tous les Summary nodes:
   MATCH (s:Summary)
   WHERE s.embedding IS NOT NULL
   WITH s, vector.similarity.cosine(s.embedding, $queryEmbedding) as similarity
   RETURN s, similarity

4. Calculer score final pour chaque summary:
   - Summary L3 "auth refactoring", similarity=0.85, age=2 days
     ‚Üí score = 0.85 √ó 1.2 (L3 boost) √ó 0.93 (recency) = 0.95

   - Summary L1 "validatePassword details", similarity=0.90, age=10 days
     ‚Üí score = 0.90 √ó 1.0 √ó 0.61 = 0.55

5. Prendre top 5 summaries par score

6. Inclure dans contexte
```

### Contexte Final = Recent + RAG

```typescript
// System prompt construction

const context = `
## Recent Conversation (derniers √©changes d√©taill√©s)

Turn 8:
User: "Show me validatePassword"
Assistant: "Here's the code..."
[reasoning: Using get_function_code]
[tools: get_function_code(name="validatePassword") ‚Üí success]

Turn 9:
User: "What are its dependencies?"
Assistant: "It depends on hashPassword..."
[reasoning: Using get_dependents]
[tools: get_dependents(scopeName="validatePassword") ‚Üí 2 dependencies found]

---

## Relevant Past Context (RAG sur historique)

[L3 Summary - Auth Refactoring Session - 2 days ago]
Conversation: "L'utilisateur a men√© une session compl√®te de refactoring du syst√®me d'authentification, explorant AuthService, UserService, et les d√©pendances..."
Actions: "Recherches multiples avec search_functions, analyses de complexit√© avec batch_analyze, extraction de d√©pendances avec get_dependents..."

[L2 Summary - Password Validation Analysis - 5 days ago]
Conversation: "L'utilisateur a analys√© en d√©tail validatePassword et checkPasswordStrength, posant des questions sur la s√©curit√©..."
Actions: "Recherche de fonctions de validation, analyse de code avec get_function_code, suggestions de refactoring..."

[L1 Summary - hashPassword Implementation - 3 days ago]
Conversation: "L'utilisateur a demand√© l'impl√©mentation de hashPassword. J'ai expliqu√© l'utilisation de bcrypt..."
Actions: "R√©cup√©ration du code avec get_function_code, analyse des d√©pendances externes..."

---

Now answer the user's question with this context.
`;
```

## üìù Structure des R√©sum√©s

### Format Structur√©

Chaque summary contient **deux parties distinctes** :

```typescript
interface SummaryContent {
  conversation_summary: string;   // 3-4 lignes max
  actions_summary: string;        // 3-4 lignes max
}
```

### Partie 1: Conversation Summary

**Focus**: Questions de l'utilisateur et r√©ponses de l'assistant

**Format**: "L'utilisateur a demand√© X, donc je lui ai r√©pondu Y..."

**Exemple**:
```
L'utilisateur a demand√© d'analyser la fonction validatePassword pour comprendre
son fonctionnement. Je lui ai expliqu√© qu'elle utilise bcrypt pour hasher les
mots de passe et v√©rifie la force via checkPasswordStrength. Il a ensuite demand√©
les d√©pendances, j'ai list√© hashPassword et checkPasswordStrength.
```

### Partie 2: Actions Summary

**Focus**: Tool calls effectu√©s par l'assistant avec leurs r√©sultats

**Format**: Lier reasoning + tool calls de mani√®re narrative

**Exemple**:
```
J'ai d'abord utilis√© search_functions(query="password validation") qui a retourn√©
15 fonctions. Puis j'ai appel√© get_function_code(name="validatePassword") pour
r√©cup√©rer l'impl√©mentation (157 lignes). Ensuite get_dependents(scopeName="validatePassword")
a r√©v√©l√© 2 d√©pendances: hashPassword et checkPasswordStrength.
```

### G√©n√©ration avec LLM

**Prompt pour L1** (r√©sume messages bruts):
```typescript
const messagesFormatted = `
Turn 1:
User: "Show me validatePassword"
Assistant: "Here's the implementation... [code]"
Reasoning: "I'll use get_function_code to retrieve the full implementation"
Tools:
  - get_function_code(name="validatePassword")
    ‚Üí Success: Returned 157 lines of code

Turn 2:
User: "What are its dependencies?"
Assistant: "It depends on two functions: hashPassword and checkPasswordStrength..."
Reasoning: "I'll use get_dependents to find all functions that validatePassword calls"
Tools:
  - get_dependents(scopeName="validatePassword")
    ‚Üí Success: Found 2 dependencies
`;

const prompt = `Summarize this conversation segment into two parts:

1. **Conversation Summary** (3-4 lines max):
   Focus on what the user asked and what you answered.
   Format: "L'utilisateur a demand√© X, donc je lui ai r√©pondu Y..."

2. **Actions Summary** (3-4 lines max):
   Focus on the tools you called and their results, linked with your reasoning.
   Format: "J'ai utilis√© tool_name(args) qui a retourn√© X, puis..."

Be factual and preserve critical details.`;

const result = await llm.call({
  prompt,
  input: messagesFormatted,
  outputSchema: {
    conversation_summary: { type: 'string', maxLength: 500 },
    actions_summary: { type: 'string', maxLength: 500 }
  }
});
```

**Prompt pour L2+** (r√©sume des summaries L1):
```typescript
const l1Summaries = `
L1 Summary #1 (chars 0-10k):
  Conversation: "L'utilisateur a demand√© d'analyser validatePassword..."
  Actions: "J'ai utilis√© search_functions puis get_function_code..."

L1 Summary #2 (chars 10k-20k):
  Conversation: "L'utilisateur a demand√© les d√©pendances de validatePassword..."
  Actions: "J'ai utilis√© get_dependents qui a trouv√© 2 fonctions..."

L1 Summary #3 (chars 20k-30k):
  Conversation: "L'utilisateur a demand√© des suggestions de refactoring..."
  Actions: "J'ai utilis√© batch_analyze sur les 3 fonctions li√©es..."
`;

const prompt = `Synthesize these conversation summaries into a higher-level summary.

Combine them into two coherent parts:

1. **Conversation Summary** (3-4 lines max):
   What were the main topics and questions across all these segments?

2. **Actions Summary** (3-4 lines max):
   What were the main tools used and patterns of investigation?

Maintain chronological flow if relevant.`;

const result = await llm.call({
  prompt,
  input: l1Summaries,
  outputSchema: {
    conversation_summary: { type: 'string', maxLength: 500 },
    actions_summary: { type: 'string', maxLength: 500 }
  }
});
```

## üîó Formatage des Tool Calls avec Reasoning

### Principe

Au lieu de stocker s√©par√©ment:
- Liste de reasonings
- Liste de tool calls

On **lie** chaque tool call √† son reasoning dans le formatage.

### Structure dans Message

```typescript
interface Message {
  uuid: string;
  content: string;         // R√©ponse de l'assistant
  reasoning?: string;      // Thinking global (optionnel)
  tool_calls?: ToolCall[]; // Tools appel√©s
}

interface ToolCall {
  tool_name: string;
  arguments: any;
  reasoning?: string;      // Reasoning sp√©cifique √† ce tool call
  result: any;
  success: boolean;
  duration_ms: number;
}
```

### Exemple de Formatage pour R√©sum√©

Quand on pr√©pare les messages pour le r√©sum√© L1, on les formate ainsi:

```
Turn 5:
User: "Find authentication functions and analyze them"
On **lie** chaque tool call √† son reasoning dans le formatage.

### Structure dans Message

```typescript
interface Message {
  uuid: string;
  content: string;         // R√©ponse de l'assistant
  reasoning?: string;      // Thinking global (optionnel)
  tool_calls?: ToolCall[]; // Tools appel√©s
}

interface ToolCall {
  tool_name: string;
  arguments: any;
  reasoning?: string;      // Reasoning sp√©cifique √† ce tool call (NEW)
  result: any;
  success: boolean;
  duration_ms: number;
  iteration?: number;      // Si per-item mode
}
```

### Exemple de Formatage pour R√©sum√©

Quand on pr√©pare les messages pour le r√©sum√© L1, on les formate ainsi:

```
Turn 5:
User: "Find authentication functions and analyze them"


# note lucie: personnae .luciform additionnelle pour l'agent dans sa r√©ponse finale, pour donner un petit caract√®re au llm:
voir /home/luciedefraiteur/lr_hmm/personas
pour expliquer: une personnae .luciform est un xml qui est envoy√© au llm, il contient des symboles qui doivent etre pass√©s aussi au llm.


#note lucie 2: generation de relationship par topic, et de topics, quand on fait des r√©sum√©s, possibilit√© de rechercher des topics, merge de topics trigger√©s quand ceux ci sont propos√©s proches par un llm (quand g√©n√©ration r√©sum√© l + 1), 

possibilit√© de contraindre une recherche par topic

#note lucie 3: si evalution llm propose un merge de topics mais avec un score pas tr√®s haut de confidence, possibilit√© de g√©n√©rer plutot des relationship "related topics" pour un topic donn√©.