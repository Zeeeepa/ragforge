# Plan: RÃ©Ã©criture du SystÃ¨me d'Ingestion

**Date**: 30 dÃ©cembre 2025
**Statut**: Ã€ faire

## Contexte

Le fichier `incremental-ingestion.ts` (~2350 lignes) est devenu trop complexe:
- MÃ©lange parsing, ingestion, hash checking, state machine, references
- Logique de capture/restore embeddings inutile
- Modes d'ingestion confus (`true`, `'both'`, `'files'`, `'content'`, `false`)
- Pattern "delete + recreate + restore" fragile
- DÃ©finitions Ã©parpillÃ©es (`FIELD_MAPPING`, `MULTI_EMBED_CONFIGS`) faciles Ã  oublier

## Objectifs

1. **SÃ©paration des responsabilitÃ©s** - Un fichier = une responsabilitÃ©
2. **Update in place** - MERGE au lieu de delete/recreate
3. **State machine** - `_state` au lieu de `embeddingsDirty`
4. **Interface parser unifiÃ©e** - Force les conventions pour tous les types de fichiers
5. **SimplicitÃ©** - Moins de code, moins de bugs

---

## Architecture: Interface Parser UnifiÃ©e

### ProblÃ¨me actuel

Les dÃ©finitions sont Ã©parpillÃ©es et faciles Ã  oublier:
- `UniversalSourceAdapter` â†’ route vers les parsers
- `FIELD_MAPPING` (node-schema.ts) â†’ extraction de contenu
- `MULTI_EMBED_CONFIGS` (embedding-service.ts) â†’ queries d'embedding
- `text-chunker.ts` â†’ chunking du texte

Si on ajoute un nouveau parser, on doit penser Ã  modifier 3-4 fichiers diffÃ©rents.

### Solution: Interface `ContentParser`

Chaque parser **DOIT** implÃ©menter cette interface, qui inclut la dÃ©finition
de comment extraire le contenu embeddable:

```typescript
// packages/core/src/ingestion/parser-types.ts

/**
 * Interface que tous les parsers doivent implÃ©menter.
 * Force la dÃ©finition des champs pour l'embedding.
 */
interface ContentParser {
  /** Nom unique du parser */
  readonly name: string;

  /** Extensions supportÃ©es (ex: ['.md', '.mdx']) */
  readonly supportedExtensions: string[];

  /** DÃ©finition des types de nodes crÃ©Ã©s par ce parser */
  readonly nodeTypes: NodeTypeDefinition[];

  /** Parse un fichier et retourne les nodes */
  parse(input: ParseInput): Promise<ParseOutput>;
}

/**
 * DÃ©finition d'un type de node avec ses champs d'extraction.
 * OBLIGATOIRE pour chaque type de node crÃ©Ã© par le parser.
 */
interface NodeTypeDefinition {
  /** Label Neo4j (ex: 'Scope', 'MarkdownSection') */
  label: string;

  /**
   * Extraction des champs pour embedding.
   * Ces fonctions sont utilisÃ©es par EmbeddingService.
   */
  fields: {
    /** Nom/titre/signature - pour embedding_name */
    name: (node: any) => string;
    /** Contenu principal - pour embedding_content */
    content: (node: any) => string | null;
    /** Description/docstring - pour embedding_description */
    description?: (node: any) => string | null;
    /** Localisation (fichier, URL) */
    location: (node: any) => string;
  };

  /** PropriÃ©tÃ©s requises sur ce type de node */
  requiredProps: string[];

  /** PropriÃ©tÃ© utilisÃ©e pour le hash de contenu */
  contentHashField: string;

  /** Configuration de chunking (optionnel) */
  chunking?: {
    enabled: boolean;
    maxSize: number;
    strategy: 'paragraph' | 'sentence' | 'code';
  };
}
```

### Exemple: MarkdownParser

```typescript
class MarkdownParser implements ContentParser {
  readonly name = 'markdown';
  readonly supportedExtensions = ['.md', '.mdx'];

  readonly nodeTypes: NodeTypeDefinition[] = [
    {
      label: 'MarkdownDocument',
      fields: {
        name: (n) => n.title || n.file,
        content: () => null,  // Pas de contenu propre au document
        description: (n) => n.frontMatter ? JSON.stringify(n.frontMatter) : null,
        location: (n) => n.file,
      },
      requiredProps: ['uuid', 'file'],
      contentHashField: 'rawContent',
    },
    {
      label: 'MarkdownSection',
      fields: {
        name: (n) => n.title || `Section level ${n.level}`,
        content: (n) => n.ownContent || n.content,
        description: () => null,
        location: (n) => n.file,
      },
      requiredProps: ['uuid', 'title', 'level', 'content'],
      contentHashField: 'content',
      chunking: { enabled: true, maxSize: 4000, strategy: 'paragraph' },
    },
  ];

  async parse(input: ParseInput): Promise<ParseOutput> {
    // ImplÃ©mentation...
  }
}
```

### Auto-gÃ©nÃ©ration depuis les dÃ©finitions

Le systÃ¨me gÃ©nÃ¨re automatiquement:

```typescript
// ParserRegistry collecte tous les parsers
class ParserRegistry {
  private parsers: Map<string, ContentParser> = new Map();

  register(parser: ContentParser) {
    this.parsers.set(parser.name, parser);
  }

  // GÃ©nÃ¨re FIELD_MAPPING depuis tous les nodeTypes
  getFieldMapping(): Record<string, NodeFieldMapping> {
    const mapping: Record<string, NodeFieldMapping> = {};
    for (const parser of this.parsers.values()) {
      for (const nodeDef of parser.nodeTypes) {
        mapping[nodeDef.label] = {
          title: nodeDef.fields.name,
          content: nodeDef.fields.content,
          description: nodeDef.fields.description || (() => null),
          location: nodeDef.fields.location,
        };
      }
    }
    return mapping;
  }

  // GÃ©nÃ¨re les configs d'embedding depuis tous les nodeTypes
  getEmbedConfigs(): EmbedConfig[] {
    // ...
  }

  // Trouve le parser pour une extension
  getParserForFile(filePath: string): ContentParser | null {
    const ext = path.extname(filePath).toLowerCase();
    for (const parser of this.parsers.values()) {
      if (parser.supportedExtensions.includes(ext)) {
        return parser;
      }
    }
    return null;
  }
}
```

### Avantages

| Avant | AprÃ¨s |
|-------|-------|
| 3-4 fichiers Ã  modifier pour un nouveau type | 1 seul fichier (le parser) |
| Facile d'oublier `FIELD_MAPPING` | TypeScript force la dÃ©finition |
| Documentation sÃ©parÃ©e | La dÃ©finition EST la documentation |
| Validation manuelle | Validation automatique des props |

---

## Nouvelle Architecture

### Structure des fichiers

```
packages/core/src/ingestion/
â”œâ”€â”€ index.ts                    # Re-exports publics
â”œâ”€â”€ types.ts                    # âœ… Types partagÃ©s (existe)
â”œâ”€â”€ state-types.ts              # âœ… Types state machine (existe)
â”œâ”€â”€ node-state-machine.ts       # âœ… Gestion Ã©tats nodes (existe)
â”œâ”€â”€ change-queue.ts             # âœ… Batching changements (existe)
â”œâ”€â”€ orphan-watcher.ts           # âœ… Watch fichiers hors projet (existe)
â”‚
â”œâ”€â”€ parser-types.ts             # ðŸ†• Interface ContentParser + NodeTypeDefinition
â”œâ”€â”€ parser-registry.ts          # ðŸ†• Registry des parsers, auto-gÃ©nÃ¨re configs
â”œâ”€â”€ content-extractor.ts        # ðŸ†• Extraction + chunking unifiÃ©
â”‚
â”œâ”€â”€ orchestrator.ts             # ðŸ”„ Point d'entrÃ©e principal (simplifier)
â”œâ”€â”€ graph-merger.ts             # ðŸ†• MERGE nodes dans Neo4j
â””â”€â”€ reference-linker.ts         # ðŸ†• CrÃ©ation relations CONSUMES

packages/core/src/parsers/      # ðŸ†• Nouveau dossier pour les parsers
â”œâ”€â”€ index.ts                    # Re-exports + enregistrement auto
â”œâ”€â”€ code-parser.ts              # ðŸ”„ Refacto depuis CodeSourceAdapter
â”œâ”€â”€ markdown-parser.ts          # ðŸ”„ Refacto depuis MarkdownParser
â”œâ”€â”€ document-parser.ts          # ðŸ”„ Refacto depuis DocumentFileParser
â”œâ”€â”€ media-parser.ts             # ðŸ”„ Refacto depuis MediaFileParser
â”œâ”€â”€ data-parser.ts              # ðŸ”„ Refacto depuis DataFileParser
â””â”€â”€ web-parser.ts               # ðŸ”„ Pour WebPage
```

### ResponsabilitÃ©s

#### `orchestrator.ts` (simplifiÃ©)
Point d'entrÃ©e unique. Orchestre le flux sans logique mÃ©tier.

```typescript
class IngestionOrchestrator {
  // Ingestion initiale d'un projet
  async ingestProject(projectPath: string, options?: IngestOptions): Promise<IngestStats>

  // RÃ©-ingestion de fichiers modifiÃ©s
  async reingestFiles(files: FileChange[], projectId: string): Promise<IngestStats>

  // Marquer un fichier comme modifiÃ© (pour le watcher)
  async markFileChanged(filePath: string, projectId: string): Promise<void>
}
```

#### `graph-merger.ts` (nouveau)
Fusionne un ParsedGraph dans Neo4j avec update in place.

```typescript
class GraphMerger {
  constructor(neo4j: Neo4jClient, stateMachine: NodeStateMachine)

  // Merge nodes et relationships
  // - MERGE par UUID (pas de delete)
  // - Compare _contentHash pour dÃ©tecter changements
  // - Set _state = 'linked' si contenu changÃ©
  // - Supprime nodes orphelins (dans DB mais pas dans graph)
  async merge(graph: ParsedGraph, projectId: string): Promise<MergeStats>
}

interface MergeStats {
  created: number;      // Nouveaux nodes
  updated: number;      // Nodes avec contenu changÃ©
  unchanged: number;    // Nodes identiques
  deleted: number;      // Nodes orphelins supprimÃ©s
}
```

#### `content-hasher.ts` (nouveau)
Utilitaires pour le hashing et la comparaison.

```typescript
// Hash d'un fichier (SHA-256 du contenu brut)
function hashFile(filePath: string): Promise<string>

// Hash d'un contenu (pour nodes)
function hashContent(content: string): string

// Comparer avec les hashes existants en DB
async function getChangedFiles(
  files: string[],
  projectId: string,
  neo4j: Neo4jClient
): Promise<{ changed: string[]; unchanged: string[] }>
```

#### `reference-linker.ts` (nouveau)
CrÃ©ation des relations CONSUMES entre nodes.

```typescript
class ReferenceLinker {
  // CrÃ©er les relations CONSUMES pour un projet
  async linkReferences(projectId: string, options?: LinkOptions): Promise<LinkStats>

  // CrÃ©er les relations pour des fichiers spÃ©cifiques
  async linkFilesReferences(files: string[], projectId: string): Promise<LinkStats>
}
```

---

## Nouveau Flux d'Ingestion

### Ingestion initiale

```
1. orchestrator.ingestProject(path)
   â”‚
   â”œâ”€â–º Parser tous les fichiers â†’ ParsedGraph
   â”‚   (UniversalSourceAdapter.parse())
   â”‚
   â”œâ”€â–º graphMerger.merge(graph, projectId)
   â”‚   - MERGE tous les nodes
   â”‚   - Set _state = 'linked' (nouveaux nodes)
   â”‚
   â”œâ”€â–º referenceLinker.linkReferences(projectId)
   â”‚   - CrÃ©er relations CONSUMES
   â”‚
   â””â”€â–º Return stats
```

### RÃ©-ingestion (fichier modifiÃ©)

```
1. orchestrator.reingestFiles(changes, projectId)
   â”‚
   â”œâ”€â–º Filtrer fichiers inchangÃ©s (via rawContentHash)
   â”‚   - contentHasher.getChangedFiles()
   â”‚
   â”œâ”€â–º Parser seulement les fichiers changÃ©s
   â”‚   - UniversalSourceAdapter.parse(changedFiles)
   â”‚
   â”œâ”€â–º graphMerger.merge(graph, projectId)
   â”‚   - MERGE nodes (update in place)
   â”‚   - Compare _contentHash:
   â”‚     - ChangÃ© â†’ _state = 'linked'
   â”‚     - InchangÃ© â†’ pas de modification
   â”‚   - Supprime nodes orphelins du fichier
   â”‚
   â”œâ”€â–º referenceLinker.linkFilesReferences(changedFiles)
   â”‚   - Mettre Ã  jour relations CONSUMES
   â”‚
   â””â”€â–º Return stats
```

### Traitement des embeddings (async)

```
// SÃ©parÃ© du flux d'ingestion
EmbeddingService.generateMultiEmbeddings()
  - Query: WHERE _state = 'linked'
  - GÃ©nÃ¨re embeddings
  - Set _state = 'ready'
```

---

## GraphMerger - DÃ©tails

### Query MERGE avec state machine

```cypher
// Pour chaque type de node (Scope, MarkdownSection, etc.)
UNWIND $nodes AS nodeData
MERGE (n:Scope {uuid: nodeData.uuid})
SET n += nodeData.props,
    // Si le hash a changÃ©, marquer pour re-embedding
    n._state = CASE
      WHEN n._contentHash IS NULL THEN 'linked'           // Nouveau node
      WHEN n._contentHash <> nodeData.props.hash THEN 'linked'  // Contenu changÃ©
      ELSE COALESCE(n._state, 'linked')                   // InchangÃ©, garder Ã©tat
    END,
    n._stateChangedAt = CASE
      WHEN n._contentHash IS NULL OR n._contentHash <> nodeData.props.hash
      THEN datetime()
      ELSE n._stateChangedAt
    END,
    n._contentHash = nodeData.props.hash
```

### Suppression des orphelins

```cypher
// AprÃ¨s MERGE, supprimer les nodes du fichier qui ne sont plus dans le parse
MATCH (n:Scope {projectId: $projectId, file: $filePath})
WHERE NOT n.uuid IN $parsedUuids
DETACH DELETE n
RETURN count(n) AS deleted
```

---

## Ce qui disparaÃ®t

### Fichiers Ã  supprimer/archiver
- `runtime/adapters/incremental-ingestion.ts` (2350 lignes â†’ remplacÃ©)
- `brain/file-state-machine.ts` (fusionnÃ© avec node-state-machine)
- `ingestion/metadata-preserver.ts` (plus nÃ©cessaire)

### Concepts supprimÃ©s
- `embeddingsDirty` / `schemaDirty` â†’ remplacÃ© par `_state`
- Modes d'ingestion (`'both'`, `'files'`, `'content'`) â†’ un seul mode
- Capture/restore embeddings â†’ plus nÃ©cessaire (MERGE prÃ©serve)
- Delete + recreate â†’ update in place

---

## Plan d'implÃ©mentation

### Phase 1: Interface Parser et Registry
- [ ] `parser-types.ts` - Interfaces ContentParser, NodeTypeDefinition, ParseInput/Output
- [ ] `parser-registry.ts` - Registry avec auto-gÃ©nÃ©ration FIELD_MAPPING
- [ ] `content-extractor.ts` - Extraction unifiÃ©e avec chunking (utilise text-chunker.ts)

### Phase 2: Refactoriser les parsers existants
- [ ] `parsers/code-parser.ts` - Depuis CodeSourceAdapter
- [ ] `parsers/markdown-parser.ts` - Depuis MarkdownParser
- [ ] `parsers/document-parser.ts` - Depuis DocumentFileParser
- [ ] `parsers/media-parser.ts` - Depuis MediaFileParser
- [ ] `parsers/data-parser.ts` - Depuis DataFileParser
- [ ] `parsers/index.ts` - Auto-registration de tous les parsers

### Phase 3: Nouveau systÃ¨me d'ingestion
- [ ] `graph-merger.ts` - MERGE nodes avec state machine
- [ ] `reference-linker.ts` - CrÃ©ation relations CONSUMES
- [ ] RÃ©Ã©crire `orchestrator.ts` pour utiliser les nouveaux composants

### Phase 4: Migration EmbeddingService
- [ ] Modifier EmbeddingService pour utiliser ParserRegistry.getEmbedConfigs()
- [ ] Supprimer MULTI_EMBED_CONFIGS hardcodÃ©
- [ ] Supprimer FIELD_MAPPING hardcodÃ© (remplacÃ© par auto-gÃ©nÃ©ration)

### Phase 5: IntÃ©gration
- [ ] Mettre Ã  jour `brain-manager.ts` pour utiliser le nouveau systÃ¨me
- [ ] Mettre Ã  jour `file-watcher.ts`
- [ ] Mettre Ã  jour `brain-tools.ts`

### Phase 6: Nettoyage
- [ ] Supprimer `incremental-ingestion.ts` (~2350 lignes)
- [ ] Supprimer `file-state-machine.ts`
- [ ] Supprimer `metadata-preserver.ts`
- [ ] Supprimer `UniversalSourceAdapter` (remplacÃ© par ParserRegistry)
- [ ] Supprimer tous les `embeddingsDirty` / `schemaDirty` restants

### Phase 7: Tests
- [ ] Tests unitaires pour chaque parser
- [ ] Tests d'intÃ©gration: ingestion initiale
- [ ] Tests d'intÃ©gration: rÃ©-ingestion fichier modifiÃ©
- [ ] Tests d'intÃ©gration: gÃ©nÃ©ration embeddings

---

## Questions ouvertes

1. **Garder `rawContentHash` sur File nodes?**
   - Pro: Permet skip rapide si fichier inchangÃ©
   - Con: Ajoute complexitÃ©
   - DÃ©cision: Garder pour l'optimisation

2. **OÃ¹ mettre les fonctions de parsing?**
   - Garder dans `UniversalSourceAdapter` (runtime/adapters/)
   - L'orchestrator appelle le parser

3. **Gestion des erreurs?**
   - Utiliser `_state = 'error'` avec `_errorType` et `_errorMessage`
   - Retry automatique via state machine

---

## System Props UnifiÃ©es

Toutes les propriÃ©tÃ©s systÃ¨me utilisent le prÃ©fixe `__name__` pour Ãªtre clairement distinctes des props mÃ©tier.

```typescript
interface SystemProps {
  // === IDENTITÃ‰ (pas de prÃ©fixe - clÃ©s primaires) ===
  uuid: string;
  projectId: string;

  // === TIMESTAMPS ===
  __createdAt__: DateTime;          // PremiÃ¨re crÃ©ation du node
  __updatedAt__: DateTime;          // DerniÃ¨re modification du contenu
  __lastAccessedAt__?: DateTime;    // Dernier accÃ¨s (null pour l'instant, prÃ©vu pour cleanup)

  // === STATE MACHINE ===
  __state__: 'pending' | 'parsing' | 'parsed' | 'linking' | 'linked' | 'embedding' | 'ready' | 'skip' | 'error';
  __stateChangedAt__: DateTime;
  __parsedAt__?: DateTime;
  __linkedAt__?: DateTime;
  __embeddedAt__?: DateTime;

  // === PROVENANCE ===
  __parserName__: string;           // 'code-parser', 'markdown-parser', etc.
  __schemaVersion__: number;        // Simple numÃ©ro incrÃ©mental (1, 2, 3...)
  __embeddingProvider__?: string;   // 'gemini', 'ollama'
  __embeddingModel__?: string;      // 'text-embedding-004'

  // === CONTENT VERSIONING ===
  __contentHash__: string;          // Hash actuel du contenu
  __previousContentHash__?: string; // Hash prÃ©cÃ©dent (dÃ©tection changements)
  __contentVersion__: number;       // IncrÃ©mentÃ© Ã  chaque changement (1, 2, 3...)

  // === SOURCE ===
  __sourceModifiedAt__?: DateTime;  // mtime du fichier source (pour dÃ©tection rapide)

  // === ERREUR ===
  __errorType__?: 'parse' | 'link' | 'embed';
  __errorMessage__?: string;
  __errorAt__?: DateTime;
  __retryCount__?: number;          // Nombre de tentatives
}
```

### RÃ¨gles de mise Ã  jour

| Ã‰vÃ©nement | Props mises Ã  jour |
|-----------|-------------------|
| CrÃ©ation node | `__createdAt__`, `__state__='pending'`, `__stateChangedAt__`, `__contentHash__`, `__contentVersion__=1`, `__parserName__`, `__schemaVersion__` |
| Contenu modifiÃ© | `__updatedAt__`, `__previousContentHash__=ancien`, `__contentHash__=nouveau`, `__contentVersion__++`, `__state__='linked'`, `__stateChangedAt__` |
| Parsing terminÃ© | `__parsedAt__`, `__state__='parsed'`, `__stateChangedAt__` |
| Linking terminÃ© | `__linkedAt__`, `__state__='linked'`, `__stateChangedAt__` |
| Embedding terminÃ© | `__embeddedAt__`, `__embeddingProvider__`, `__embeddingModel__`, `__state__='ready'`, `__stateChangedAt__` |
| Erreur | `__errorType__`, `__errorMessage__`, `__errorAt__`, `__retryCount__++`, `__state__='error'`, `__stateChangedAt__` |
| AccÃ¨s (futur) | `__lastAccessedAt__` |

---

## Estimation

| Composant | ComplexitÃ© | Lignes estimÃ©es |
|-----------|------------|-----------------|
| **Phase 1: Abstractions** | | |
| `parser-types.ts` | Faible | ~80 |
| `parser-registry.ts` | Moyenne | ~120 |
| `content-extractor.ts` | Faible | ~60 |
| **Phase 2: Parsers** | | |
| `parsers/code-parser.ts` | Haute | ~300 |
| `parsers/markdown-parser.ts` | Moyenne | ~150 |
| `parsers/document-parser.ts` | Moyenne | ~100 |
| `parsers/media-parser.ts` | Faible | ~80 |
| `parsers/data-parser.ts` | Faible | ~80 |
| **Phase 3: Ingestion** | | |
| `graph-merger.ts` | Moyenne | ~200 |
| `reference-linker.ts` | Moyenne | ~150 |
| `orchestrator.ts` (rÃ©Ã©crit) | Moyenne | ~150 |
| **Total nouveau code** | | **~1470** |
| **Code supprimÃ©** | | |
| `incremental-ingestion.ts` | | ~2350 |
| `UniversalSourceAdapter` | | ~400 |
| `FIELD_MAPPING` (node-schema) | | ~200 |
| `MULTI_EMBED_CONFIGS` (embedding-service) | | ~150 |
| Autres cleanups | | ~200 |
| **Total code supprimÃ©** | | **~3300** |

**Gain net: ~1830 lignes de moins + architecture modulaire + conventions forcÃ©es**
