# LlamaIndex + RagForge - Guide d'Int√©gration Complet

**Date**: 2025-01-12
**Objectif**: Analyse des opportunit√©s d'int√©gration de LlamaIndex dans RagForge

---

## üìã Table des Mati√®res

1. [R√©sum√© Ex√©cutif](#r√©sum√©-ex√©cutif)
2. [Multi-Provider LLMs](#1-multi-provider-llms)
3. [Multi-Provider Embeddings](#2-multi-provider-embeddings)
4. [Tool Calling Framework](#3-tool-calling-framework)
5. [Document Loaders](#4-document-loaders)
6. [Use Cases RagForge](#5-use-cases-ragforge)
7. [Plan d'Impl√©mentation](#6-plan-dimpl√©mentation)

---

## R√©sum√© Ex√©cutif

### üéØ Ce que LlamaIndex apporte √† RagForge

| Feature | Status RagForge Actuel | Avec LlamaIndex | Impact |
|---------|------------------------|-----------------|--------|
| **LLM Provider** | üîí Gemini uniquement | ‚úÖ 15+ providers | üü¢ High |
| **Embeddings** | üîí Gemini uniquement | ‚úÖ 12+ providers | üü¢ High |
| **Tool Calling** | ‚ö†Ô∏è Ad-hoc dans prompts | ‚úÖ FunctionTool standardis√© | üü° Medium |
| **Document Types** | üîí Code (TS/Python) | ‚úÖ PDF, Word, Notion, etc. | üîµ Very High |
| **Agents** | ‚ö†Ô∏è Custom implementation | ‚úÖ OpenAIAgent, ReActAgent | üü° Medium |

### ‚úÖ Quick Wins Imm√©diats

1. **Multi-Provider Embeddings** (1 semaine) ‚Üí Users choisissent leur provider
2. **Tool Calling** (1 semaine) ‚Üí Architecture plus propre
3. **Z√©ro Breaking Change** ‚Üí Garder Gemini par d√©faut

### üöÄ Vision Long Terme

- **RagForge Code** (actuel) ‚Üí Optimis√© codebases TypeScript/Python
- **RagForge Docs** (futur) ‚Üí Documentation, PDFs, Notion, Confluence
- **RagForge Business** (futur) ‚Üí Support, legal, HR documents

---

## 1. Multi-Provider LLMs

### Providers Support√©s (15+)

#### ‚òÅÔ∏è Cloud Providers

```typescript
import {
  OpenAI,        // GPT-4, GPT-3.5-turbo
  Anthropic,     // Claude 3.5 Sonnet, Opus, Haiku
  Gemini,        // Gemini 1.5 Pro/Flash ‚Üê RagForge actuel
  Groq,          // Ultra-rapide (Llama, Mixtral)
  MistralAI,     // Mistral Large/Medium/Small
  Fireworks,
  TogetherAI,
  DeepSeek,
  Perplexity
} from "llamaindex";
```

#### üè† Local/Open-Source

```typescript
import { Ollama } from "llamaindex";

// Mod√®les locaux gratuits
const ollama = new Ollama({
  model: "llama3.1:8b"    // ou mistral, gemma, codellama, etc.
});
```

### Configuration

```typescript
import { Settings, Gemini, Anthropic, Ollama } from "llamaindex";

// Option 1: Gemini (compatible avec RagForge actuel - AUCUN CHANGEMENT)
Settings.llm = new Gemini({
  apiKey: process.env.GEMINI_API_KEY,
  model: "models/gemini-1.5-pro"
});

// Option 2: Claude (si user pr√©f√®re)
Settings.llm = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
  model: "claude-3-5-sonnet-20241022"
});

// Option 3: Ollama (local, gratuit, priv√©)
Settings.llm = new Ollama({
  model: "llama3.1:70b",
  baseURL: "http://localhost:11434"
});
```

### Dans ragforge.config.yaml

```yaml
# Option 1: Garder Gemini (backward compatible)
llm:
  provider: gemini
  model: models/gemini-1.5-pro
  api_key: ${GEMINI_API_KEY}

# Option 2: Claude
llm:
  provider: anthropic
  model: claude-3-5-sonnet-20241022
  api_key: ${ANTHROPIC_API_KEY}

# Option 3: Local
llm:
  provider: ollama
  model: llama3.1:8b
  base_url: http://localhost:11434
```

**Avantages**:
- ‚úÖ Users choisissent leur provider pr√©f√©r√©
- ‚úÖ Option locale gratuite (Ollama)
- ‚úÖ Pas de vendor lock-in
- ‚úÖ Backward compatible (Gemini par d√©faut)

---

## 2. Multi-Provider Embeddings

### Providers Support√©s (12+)

#### ‚òÅÔ∏è Cloud

- **OpenAI**: `text-embedding-3-small`, `text-embedding-3-large`, `ada-002`
- **Google Gemini**: `embedding-001` ‚Üê **RagForge actuel**
- **Cohere**: `embed-v3` (multilingual)
- **VoyageAI**: Sp√©cialis√© embeddings haute qualit√©
- **JinaAI**: Optimis√© pour search
- **Azure OpenAI**
- **AWS Bedrock**
- **MistralAI**

#### üè† Local

- **Ollama**: `nomic-embed-text` (768d), `mxbai-embed-large` (1024d)
- **HuggingFace**: BERT, sentence-transformers, etc.

### Configuration S√©par√©e LLM vs Embeddings

```typescript
import { Settings, Gemini, GeminiEmbedding, OpenAIEmbedding, OllamaEmbedding } from "llamaindex";

// Sc√©nario 1: Tout en Gemini (comme RagForge actuellement)
Settings.llm = new Gemini({ model: "gemini-1.5-pro" });
Settings.embedModel = new GeminiEmbedding({ model: "embedding-001" });

// Sc√©nario 2: Mix - Gemini LLM + OpenAI embeddings
Settings.llm = new Gemini({ model: "gemini-1.5-pro" });
Settings.embedModel = new OpenAIEmbedding({
  model: "text-embedding-3-small",
  dimensions: 1536  // Meilleure qualit√© que Gemini pour certains cas
});

// Sc√©nario 3: 100% local (z√©ro co√ªt, privacit√© totale)
Settings.llm = new Ollama({ model: "llama3.1" });
Settings.embedModel = new OllamaEmbedding({
  model: "nomic-embed-text"  // 768 dimensions, excellente qualit√©
});
```

### Adapter dans RagForge

```typescript
// packages/runtime/src/embeddings/llamaindex-adapter.ts

import { Settings, GeminiEmbedding, OpenAIEmbedding, OllamaEmbedding } from "llamaindex";

export class LlamaIndexEmbeddingAdapter {
  constructor(config: EmbeddingConfig) {
    Settings.embedModel = this.createProvider(config);
  }

  private createProvider(config: EmbeddingConfig) {
    switch (config.provider) {
      case 'gemini':
        return new GeminiEmbedding({
          apiKey: config.apiKey || process.env.GEMINI_API_KEY,
          model: config.model || "embedding-001"
        });

      case 'openai':
        return new OpenAIEmbedding({
          apiKey: config.apiKey || process.env.OPENAI_API_KEY,
          model: config.model || "text-embedding-3-small",
          dimensions: config.dimension || 1536
        });

      case 'ollama':
        return new OllamaEmbedding({
          model: config.model || "nomic-embed-text",
          baseURL: config.baseUrl || "http://localhost:11434"
        });

      default:
        throw new Error(`Unknown embedding provider: ${config.provider}`);
    }
  }

  async embed(text: string): Promise<number[]> {
    return await Settings.embedModel.getTextEmbedding(text);
  }

  async embedBatch(texts: string[]): Promise<number[][]> {
    return Promise.all(texts.map(t => this.embed(t)));
  }
}
```

### Config ragforge.config.yaml

```yaml
embeddings:
  provider: gemini        # ou openai, ollama, cohere, voyage
  model: embedding-001
  dimension: 768
  # api_key: ${GEMINI_API_KEY}  # optionnel si d√©j√† dans .env
```

### Comparaison des Providers

| Provider | Dim | Co√ªt (1M tokens) | Qualit√© | Latence | Use Case |
|----------|-----|------------------|---------|---------|----------|
| **Gemini** | 768 | Gratuit (beta) | ‚≠ê‚≠ê‚≠ê‚≠ê | üü¢ Rapide | General purpose |
| **OpenAI 3-small** | 1536 | $0.02 | ‚≠ê‚≠ê‚≠ê‚≠ê | üü¢ Rapide | Balance co√ªt/qualit√© |
| **OpenAI 3-large** | 3072 | $0.13 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | üü° Moyen | Max qualit√© |
| **Ollama (nomic)** | 768 | $0.00 (local) | ‚≠ê‚≠ê‚≠ê‚≠ê | üü¢ Tr√®s rapide | Privacit√©/gratuit |
| **Voyage** | 1024 | $0.05 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | üü° Moyen | Domain-specific |
| **Cohere v3** | 1024 | $0.10 | ‚≠ê‚≠ê‚≠ê‚≠ê | üü¢ Rapide | Multilingual |

---

## 3. Tool Calling Framework

### Probl√®me Actuel

RagForge construit tools **manuellement dans les prompts**:
- Pas de validation de sch√©ma
- Pas de type safety
- Difficile d'ajouter de nouveaux tools
- Code dupliqu√©

### Solution: FunctionTool

```typescript
import { FunctionTool, OpenAIAgent } from "llamaindex";
import { createRagClient } from "@luciformresearch/ragforge-runtime";

const rag = createRagClient(config);

// 1. Tool: Semantic Search
const searchTool = FunctionTool.from(
  async ({ query, topK }: { query: string; topK?: number }) => {
    return await rag.scope()
      .semanticSearchBySource(query, { topK: topK || 10 })
      .execute();
  },
  {
    name: "search_code",
    description: "Search code entities using semantic embeddings",
    parameters: {
      type: "object",
      properties: {
        query: {
          type: "string",
          description: "Natural language query (e.g., 'authentication functions')"
        },
        topK: {
          type: "number",
          description: "Number of results",
          default: 10
        }
      },
      required: ["query"]
    }
  }
);

// 2. Tool: Traverse Relationships
const traverseTool = FunctionTool.from(
  async ({ entityId, relationship, depth }: {
    entityId: string;
    relationship: string;
    depth?: number;
  }) => {
    const entity = await rag.scope().findById(entityId);
    return await entity.traverse(relationship, depth || 1);
  },
  {
    name: "traverse_graph",
    description: "Traverse relationships in the code graph",
    parameters: {
      type: "object",
      properties: {
        entityId: { type: "string" },
        relationship: {
          type: "string",
          enum: ["IMPORTS", "CALLS", "REFERENCES", "DEFINES"]
        },
        depth: { type: "number", default: 1 }
      },
      required: ["entityId", "relationship"]
    }
  }
);

// 3. Agent avec tools
const agent = new OpenAIAgent({
  llm: new Gemini({ apiKey: process.env.GEMINI_API_KEY }), // ‚Üê Gemini!
  tools: [searchTool, traverseTool],
  verbose: true
});

// 4. Usage
const response = await agent.chat({
  message: "Find all JWT authentication functions and show their dependencies"
});

console.log(response.message.content);
```

### RagForgeToolkit (Wrapper Complet)

```typescript
// packages/runtime/src/integrations/llamaindex-toolkit.ts

export class RagForgeToolkit {
  constructor(private rag: RagClient) {}

  createTools(): FunctionTool[] {
    return [
      this.createSearchTool(),
      this.createFilterTool(),
      this.createTraverseTool(),
      this.createRerankTool(),
      this.createFindByIdTool()
    ];
  }

  createAgent(systemPrompt?: string): OpenAIAgent {
    return new OpenAIAgent({
      tools: this.createTools(),
      systemPrompt: systemPrompt || this.getDefaultPrompt(),
      verbose: true
    });
  }

  private getDefaultPrompt(): string {
    return `You are a code analysis assistant with access to a Neo4j knowledge graph.

Available tools:
- search_code: Find code by semantic search
- filter_by: Filter entities by properties
- traverse_graph: Explore relationships
- rerank_results: Re-rank with LLM reasoning
- find_by_id: Get entity by ID

Use these tools to answer questions about code structure and dependencies.`;
  }
}

// Usage simple
const toolkit = new RagForgeToolkit(rag);
const agent = toolkit.createAgent();

const answer = await agent.chat({
  message: "Analyze the security of our authentication module"
});
```

**Avantages**:
- ‚úÖ Validation automatique
- ‚úÖ Type safety TypeScript
- ‚úÖ Compatible tous LLM providers
- ‚úÖ Standardis√© (OpenAI/Anthropic format)
- ‚úÖ Error handling int√©gr√©

---

## 4. Document Loaders

### Built-in Readers (Core Package)

LlamaIndex TypeScript inclut nativement:

```typescript
import {
  PDFReader,           // .pdf
  MarkdownReader,      // .md
  JSONReader,          // .json
  CSVReader,           // .csv
  DocxReader,          // .docx (Word)
  HTMLReader,          // .html
  TextFileReader,      // .txt
  ImageReader,         // .jpg, .png, .gif
  SimpleDirectoryReader // Lit tout un dossier
} from "llamaindex";

// Exemple: Lire tous les PDFs d'un dossier
const reader = new SimpleDirectoryReader();
const documents = await reader.loadData("./company-docs");

// documents = [Document, Document, ...]
// Chaque Document a: text, metadata, etc.
```

### Readers Additionnels (@llamaindex/readers)

**Installation**:
```bash
npm install @llamaindex/readers
```

**Disponibles** (confirm√©s dans la documentation):
- `@llamaindex/readers/pdf` - PDFs
- `@llamaindex/readers/markdown` - Markdown
- `@llamaindex/readers/json` - JSON
- `@llamaindex/readers/csv` - CSV
- `@llamaindex/readers/notion` - Notion pages
- `@llamaindex/readers/discord` - Discord messages

### LlamaParse (Service Cloud)

**LlamaParse** = Service premium pour parsing avanc√©:
- üìä **Tables** ‚Üí Markdown structur√©
- üñºÔ∏è **Images** ‚Üí OCR extraction
- üìê **Layouts complexes** ‚Üí Pr√©servation structure
- üåç **Multilingue** ‚Üí Support 85+ langues

```typescript
import { LlamaParseReader } from "llamaindex";

const parser = new LlamaParseReader({
  apiKey: process.env.LLAMA_CLOUD_API_KEY,
  resultType: "markdown",  // ou "text" ou "json"
  language: "fr"
});

const docs = await parser.loadData("./complex-report.pdf");
```

**Pricing**: 1000 pages/jour gratuit, puis $0.003/page

### Readers Probables (Bas√© sur Python)

Ces readers existent en **Python** et devraient √™tre disponibles en TypeScript (√† v√©rifier):

#### üìÑ Documents
- Google Docs/Sheets/Slides
- Excel (.xlsx)
- PowerPoint (.pptx)
- Obsidian notes

#### üó£Ô∏è Communication
- Slack
- Discord ‚úÖ (confirm√©)
- Email (Gmail)
- Telegram

#### üóÑÔ∏è Databases
- MongoDB
- PostgreSQL
- MySQL
- Redis

#### üåê Web & Cloud
- Confluence
- GitHub repos
- GitLab repos
- Web scraping
- RSS feeds
- Google Drive
- Dropbox
- OneDrive

**Note**: Pour la liste exacte TypeScript, il faut check le repo GitHub packages/readers/

---

## 5. Use Cases RagForge

### Use Case 1: RagForge Code (Actuel) + LlamaIndex

**Am√©lioration imm√©diate** sans changer le domaine:

```yaml
# ragforge.config.yaml
name: company-codebase
domain: code

# NOUVEAU: Multi-provider embeddings
embeddings:
  provider: ollama  # Gratuit + local
  model: nomic-embed-text
  dimension: 768

# NOUVEAU: Multi-provider LLM
llm:
  provider: anthropic  # Si user pr√©f√®re Claude
  model: claude-3-5-sonnet-20241022

entities:
  - name: Scope
    # ... reste identique
```

**B√©n√©fices**:
- ‚úÖ Users choisissent leur provider
- ‚úÖ Option locale gratuite
- ‚úÖ Pas de changement aux types g√©n√©r√©s
- ‚úÖ Agents plus puissants (FunctionTool)

### Use Case 2: RagForge Docs (Nouveau Produit)

**Nouveau framework** pour documentation d'entreprise:

```yaml
# ragforge-docs.config.yaml
name: company-knowledge-base
domain: documentation

entities:
  - name: Document
    searchable_fields:
      - { name: title, type: string }
      - { name: category, type: string }
      - { name: source, type: string }
      - { name: author, type: string }
      - { name: last_updated, type: date }
    vector_indexes:
      - name: docEmbeddings
        field: embedding
        source_field: content
        model: gemini-embedding-001
        dimension: 768

# NOUVEAU: Data sources
data_sources:
  - type: notion
    config:
      integration_token: ${NOTION_TOKEN}
      database_ids: ["abc123", "def456"]

  - type: confluence
    config:
      base_url: https://company.atlassian.net
      space_keys: ["DOCS", "WIKI"]
      username: ${CONFLUENCE_USER}
      api_token: ${CONFLUENCE_TOKEN}

  - type: pdf_directory
    config:
      path: ./company-pdfs
      recursive: true
      use_llamaparse: true  # Tables + images

  - type: markdown_directory
    config:
      path: ./docs
```

**G√©n√©ration**:
```bash
ragforge generate --config ragforge-docs.config.yaml
```

**Client g√©n√©r√©**:
```typescript
const rag = createRagClient(config);

// Recherche unifi√©e dans toutes les sources
const results = await rag
  .document()
  .semanticSearch("comment configurer OAuth 2.0?")
  .whereSource(['notion', 'confluence', 'pdf'])
  .whereCategory('security')
  .execute();

// results = [
//   { title: "OAuth Setup Guide", source: "notion", ... },
//   { title: "Security Confluence", source: "confluence", ... },
//   { title: "Auth Standards.pdf", source: "pdf", ... }
// ]
```

### Use Case 3: RagForge Mixed (Code + Docs)

**Combiner** code ET documentation:

```yaml
name: full-stack-knowledge
domain: mixed

entities:
  - name: CodeEntity
    # Parser TypeScript/Python

  - name: Document
    # Loaders LlamaIndex

data_sources:
  - type: code_parser
    config:
      languages: [typescript, python]
      root: ./src

  - type: notion
    config: { ... }

  - type: confluence
    config: { ... }
```

**Query qui search partout**:
```typescript
const results = await rag
  .search("how does authentication work?")  // Generic search
  .execute();

// Retourne:
// - Code: AuthService.ts, login(), validateToken()
// - Docs: "OAuth Setup Guide" (Notion), "Security Best Practices" (Confluence)
```

---

## 6. Plan d'Impl√©mentation

### Phase 1: Multi-Provider Support (Week 1-2)

**Objectif**: Permettre aux users de choisir leur provider

**Tasks**:
- [ ] `npm install llamaindex`
- [ ] Cr√©er `LlamaIndexEmbeddingAdapter`
- [ ] Ajouter config `embeddings.provider` dans YAML
- [ ] Backward compatible (Gemini par d√©faut)
- [ ] Tests avec Gemini, OpenAI, Ollama
- [ ] Documentation

**Effort**: üü¢ Low
**Impact**: üü¢ High
**Risque**: üü¢ Low

**Deliverable**: Users peuvent faire:
```yaml
embeddings:
  provider: ollama  # ou gemini, openai
  model: nomic-embed-text
```

### Phase 2: Tool Calling Framework (Week 2-3)

**Objectif**: Architecture propre pour agents

**Tasks**:
- [ ] Cr√©er `RagForgeToolkit` class
- [ ] Convertir 5 op√©rations en FunctionTools:
  - semantic_search
  - filter_by
  - traverse_graph
  - rerank_results
  - find_by_id
- [ ] Cr√©er agent example
- [ ] Tests d'int√©gration
- [ ] Documentation

**Effort**: üü¢ Low
**Impact**: üü° Medium
**Risque**: üü¢ Low

**Deliverable**:
```typescript
const toolkit = new RagForgeToolkit(rag);
const agent = toolkit.createAgent();
await agent.chat({ message: "..." });
```

### Phase 3: Document Loaders (Week 4-8)

**Objectif**: RagForge pour documents (nouveau produit)

**Tasks**:
- [ ] Design `data_sources` section dans YAML
- [ ] Int√©grer SimpleDirectoryReader (PDF, Word, etc.)
- [ ] Int√©grer Notion reader
- [ ] Int√©grer Confluence reader
- [ ] Adapter generator pour documents
- [ ] Nouvelle entity "Document"
- [ ] Tests end-to-end
- [ ] Documentation + examples

**Effort**: üü° Medium
**Impact**: üîµ Very High
**Risque**: üü° Medium

**Deliverable**: RagForge fonctionne pour documentation!

### Phase 4: Advanced Features (Week 9-12)

**Objectif**: Features avanc√©es

**Tasks**:
- [ ] Multi-source query engine
- [ ] ReActAgent (multi-step reasoning)
- [ ] Workflows event-driven
- [ ] LlamaParse integration (tables, images)
- [ ] Hybrid search (code + docs)

**Effort**: üü° Medium
**Impact**: üü¢ High
**Risque**: üü° Medium

---

## Installation & Quick Start

### 1. Installation

```bash
cd /home/luciedefraiteur/LR_CodeRag/ragforge/packages/runtime

# Core
npm install llamaindex

# Providers (optionnels)
npm install @llamaindex/google      # Gemini
npm install @llamaindex/openai      # OpenAI
npm install @llamaindex/anthropic   # Claude

# Readers (optionnels)
npm install @llamaindex/readers
```

### 2. Test Multi-Provider Embeddings

```typescript
import { Settings, GeminiEmbedding, OllamaEmbedding } from "llamaindex";

// Test 1: Gemini (actuel RagForge)
Settings.embedModel = new GeminiEmbedding({
  apiKey: process.env.GEMINI_API_KEY
});

const embedding1 = await Settings.embedModel.getTextEmbedding("hello world");
console.log("Gemini embedding:", embedding1.length);  // 768

// Test 2: Ollama (local, gratuit)
Settings.embedModel = new OllamaEmbedding({
  model: "nomic-embed-text"
});

const embedding2 = await Settings.embedModel.getTextEmbedding("hello world");
console.log("Ollama embedding:", embedding2.length);  // 768
```

### 3. Test Tool Calling

```typescript
import { FunctionTool, OpenAIAgent, Gemini } from "llamaindex";

// Cr√©er un tool simple
const sumTool = FunctionTool.from(
  ({ a, b }: { a: number; b: number }) => a + b,
  {
    name: "sum",
    description: "Add two numbers",
    parameters: {
      type: "object",
      properties: {
        a: { type: "number" },
        b: { type: "number" }
      },
      required: ["a", "b"]
    }
  }
);

// Agent avec Gemini
const agent = new OpenAIAgent({
  llm: new Gemini({ apiKey: process.env.GEMINI_API_KEY }),
  tools: [sumTool]
});

const response = await agent.chat({
  message: "What is 5 + 7?"
});

console.log(response.message.content);  // "5 + 7 = 12"
```

### 4. Test Document Loading

```typescript
import { SimpleDirectoryReader, PDFReader } from "llamaindex";

// Lire tous les fichiers d'un dossier
const reader = new SimpleDirectoryReader();
const documents = await reader.loadData("./test-docs");

console.log(`Loaded ${documents.length} documents`);
documents.forEach(doc => {
  console.log(`- ${doc.metadata.file_name}: ${doc.text.length} chars`);
});

// Lire un PDF sp√©cifique
const pdfReader = new PDFReader();
const pdfDocs = await pdfReader.loadData("./test.pdf");
console.log(`PDF content: ${pdfDocs[0].text}`);
```

---

## Conclusion

### R√©sum√© des B√©n√©fices

| Feature | Effort | Impact | ROI |
|---------|--------|--------|-----|
| **Multi-Provider Embeddings** | üü¢ Low (1-2 sem) | üü¢ High | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Tool Calling** | üü¢ Low (1-2 sem) | üü° Medium | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Document Loaders** | üü° Medium (4-6 sem) | üîµ Very High | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Advanced Agents** | üü° Medium (3-4 sem) | üü¢ High | ‚≠ê‚≠ê‚≠ê‚≠ê |

### Recommandation

**Start Small** (Phase 1-2):
1. Multi-provider embeddings (1-2 semaines)
2. Tool calling framework (1-2 semaines)

**Total**: 2-4 semaines, impact imm√©diat, z√©ro breaking change

**Expand Later** (Phase 3-4):
- Document loaders ‚Üí **Nouveau march√©** (docs, support, legal)
- Advanced features ‚Üí Diff√©renciation

### Next Steps

1. ‚úÖ Installer LlamaIndex: `npm install llamaindex`
2. ‚úÖ Tester multi-provider embeddings (Gemini vs Ollama)
3. ‚úÖ POC RagForgeToolkit avec 2-3 tools
4. ‚úÖ D√©cider: Phase 1-2 ou direct Phase 3?

---

**Questions? Pr√™t √† d√©marrer?** üöÄ
